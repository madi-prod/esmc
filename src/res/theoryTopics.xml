<?xml version="1.0" encoding="UTF-8"?>
<sections>
    <section val="1" name="Вычислительные методы">
        <topic>
            <name>1. Вычислительная погрешность</name>
            <content>
                1.	Вычислительная погрешность и методы ее оценки
                    •	правило подсчета цифр,
                    •	систематический учет погрешностей,
                    •	метод границ).
                2.	Правила округления.
                3.	Верные цифры.
                4.	Значащие цифры.
                5.	Машинная погрешность.

                КРАТКАЯ ТЕОРИЯ
                Под погрешностью понимается величина, характеризующая точность результата. Различают три основных вида погрешностей:
                1) Погрешность задачи – связана с приближенным характером исходной содержательной модели (в частности, с невозможностью учесть все факторы в процессе изучения моделируемого явления), а также ее математического описания, параметрами которого служат обычно приближенные числа (например, из-за принципиальной невозможности выполнения абсолютно точных измерений). Для вычислителя погрешность задачи следует считать неустранимой (безусловной), хотя постановщик задачи иногда может ее изменить.
                2) Погрешность метода – связанна со способом решения поставленной математической задачи и появляющаяся в результате подмены исходной математической модели другой или конечной последовательностью других, например, линейных моделей. При создании численных методов закладывается возможность отслеживания таких погрешностей и доведения их до сколь угодно малого уровня. Отсюда естественно отношение к погрешности метода как к устранимой (или условной).
                3) Погрешность действий обусловлена необходимостью выполнять арифметические операции над числами, усеченными до количества разрядов, зависящего от применяемой вычислительной техники (если, разумеется, не используются специальные программные средства, реализующие, например, арифметику рациональных чисел).
                Эти погрешности в сумме дают полную погрешность результата решения задачи. Первый тип погрешности служит ориентиром точности, с которой следует рассчитывать математическую модель. Нет смысла решать задачу существенно точнее, чем это диктуется неопределимостью исходных данных, т.е. погрешность метода подчиняют погрешности задачи. Так как при выводе оценок погрешностей численных методов обычно исходят из предположения, что все операции над числами выполняются точно, то погрешность округлений не должна существенно отражаться на результатах реализации методов, т.е. должна подчиняться погрешности метода. Влияние погрешностей округлений не следует упускать из вида ни на стадии отбора и алгоритмизации численных методов, ни при выборе вычислительных и программных средств, ни при выполнении отдельных действий и вычислении значений функций.

                1.	Вычислительная погрешность.
                Рассмотрим процесс округления чисел, записанных в десятичной системе. Оно производится по правилу первой отбрасываемой цифры:
                •	если первая из отбрасываемых цифр меньше 5, то оставляемые десятичные знаки сохраняются без изменения;
                •	если первая из отбрасываемых цифр больше 5, то последняя оставляемая цифра увеличивается на единицу;
                •	если первая из отбрасываемых цифр равна 5, а за ней идут не нули, то последняя оставляемая цифра увеличивается на единицу;
                •	если первая из отбрасываемых цифр равна 5 и все значащие цифры, идущие за ней, – нули, то последняя оставляемая цифра увеличивается на единицу, если она нечетная, и остаётся без изменения, если – чётная.
                Это правило округления обеспечивает увеличение абсолютной погрешности не более, чем на половину последнего сохраняемого разряда.
                При округлении целого числа отброшенные знаки не следует заменять нулями, надо применять умножение на соответствующие степени 10. Например: если число c=250331 надо округлить до пяти десятичных знаков после запятой, то имеем c*=2.5 105.
                В основе процессов округления лежит идея минимальности разности числа и его округлённого значения.
                Поведение вычислительной погрешности зависит от правила округлений и алгоритма численного решения задачи.

                2.	 Неустранимая погрешность.
                Неустранимая погрешность – это погрешность, связанная с ошибками в исходной информации. Причинами этих ошибок может быть, например, неточность измерений, невозможность представления данной величины конечной дробью. Обычно различают абсолютную и относительную формы ошибок.
                2.1.	Погрешность чисел.
                Значащая цифра приближённого числа в десятичной записи – это любая его цифра, в том числе и нуль, если он стоит между отличными от нуля цифрами или после них как представитель сохраняемых разрядов числа.
                Если известно, что c=3200 (т.е. точное число), то для него нельзя использовать запись c=3.2 103, ибо тем самым два нуля переводятся в разряд незначащих цифр.
                Пусть X – точное значение величины, а X* – её приближённое значение.
                Абсолютной погрешностью числа X* называется величина DX*, удовлетворяющая условию ½X-X*½£DX*. Относительной погрешностью называется некоторая величина dX*, удовлетворяющая условию
                .
                Абсолютные и относительные погрешности числа принято округлять только в большую сторону, так как при округлениях границы неопределённости числа, как правило, увеличиваются. По этой причине вычисления ведут с одним-двумя запасными десятичными знаками.
                Значащая цифра приближённого числа в десятичной записи – это любая его цифра, в том числе и нуль, если он стоит между отличными от нуля цифрами или после них как представитель сохраняемых разрядов числа.
                Значащая цифра называется верной, если абсолютная погрешность числа не превосходит 1/2 единицы разряда, соответствующего этой цифре.
                2.2.	Погрешность значения функции.
                Пусть есть функция f(x1, x2, …, xn). Известны приближённые значения x1*, x2*, …, xn* аргументов и соответствующие им абсолютные погрешности Dx1, Dx2, …, Dxn. Нужно определить неустранимую погрешность вычисления значения функции в точке (x1, x2, …, xn).
                Допустим, что 1) f(x1, x2, …, xn) непрерывно дифференцируема в рассматриваемой области; 2) погрешности Dx1, Dx2, …, Dxn. значительно меньше самих значений ½x1*½, ½x2*½, …, ½xn*½.
                Используя непрерывную дифференцируемость функции f и учитывая, что разность между xi* и xi по предположению мала, получим
                .	(1)
                Соотношение (1) называют линейной оценкой погрешности значения функции f в точке (x1, x2, …, xn). Из (1) следует, что относительная погрешность значения f в точке (x1, x2, …, xn) равна:

                Чтобы выразить относительную погрешность f через относительные погрешности аргументов, перепишем полученное выражение в виде:
                (2)
                2.3.	Погрешность результатов арифметических операций.
                Произведём конкретные оценки в случае простейших функций: найдём абсолютные погрешности суммы  , разности  , произведения   и частного  , считая известными абсолютные погрешности   и  .
                а) Если f(x,y)=x+y, то  ;
                ;
                б) если f(x,y)=x-y, то  ;
                ;
                в) если f(x,y)=x*y, то  ;
                ;
                г) если f(x,y)=x/y, то  ;
                .
                Наиболее распространённым видом вычислений является вычисление по готовой формуле. Чаще всего вычислитель анализирует результат в конце счёта. Если же условия задачи заставляют вести кооперационный учёт движения погрешности, то используется один из трёх способов приближённых вычислений:
                правило подсчёта цифр;
                систематический учёт погрешностей;
                метод границ.

                3.	Правило подсчёта цифр.
                При вычислении этим методом составляется обычная расчётная таблица, явный учёт погрешностей не ведётся, округления результатов промежуточных действий проводятся по следующим правилам:
                при сложении и вычитании приближённых чисел следует округлить число с меньшей абсолютной погрешностью (для десятичных дробей с большим количеством знаков после запятой) так, чтобы в нём осталось на один-два разряда больше, чем в точном числе. В результате считать верными столько десятичных знаков после запятой, сколько их в приближённом данном с наименьшим числом десятичных знаков после запятой;
                при умножении и делении двух приближённых чисел нужно округлить число с большим количеством значащих цифр так, чтобы в нём было лишь на одну значащую цифру больше, чем в другом числе. В результате считать верными столько значащих цифр, сколько их в приближённом данном с наименьшим числом значащих цифр;
                в значениях элементарных функций от приближённых значений аргумента (включая возведение в степень, извлечение и т.д.) в результате можно считать верными столько значащих цифр, сколько верных значащих цифр имеет значение аргумента;
                при записи промежуточных результатов следует сохранять на одну цифру больше, чем рекомендуют правила 1-3. В окончательном результате эта запасная цифра округляется.

                4.	Систематический учёт погрешностей.
                Метод предусматривает поэтапный подсчёт границ погрешностей всех промежуточных и окончательного результатов по правилам вычисления погрешностей, рассмотренных выше. Промежуточные результаты, также как и их погрешности, заносятся в специальную расчётную таблицу, состоящую из двух параллельно заполняемых частей – для результатов и их погрешностей.

                5.	Метод границ.
                В случае, когда не столь важно получить наиболее близкое к точному значению вычисляемой величины, сколь важно иметь абсолютно-гарантированные границы её возможных значений применяют метод границ, суть которого в следующем. Для функции u=f(x,y) из аргументов x и y необходимо вычислить f(a,b), где a и b – приближённые значения аргументов, причём совершенно точно известно, что НГa &lt; a &lt; ВГa, НГb &lt; b &lt; ВГb, где НГ и ВГ – соответственно обозначения нижней и верхней границы значений, и тогда
                f(НГa, НГb)&lt; f(a,b)&lt; f(ВГa, ВГb),
                если f возрастает по a и b, и
                f(НГa, ВГb)&lt;f(a,b)&lt; f(ВГa, НГb),
                если f возрастает по a и убывает по b.
                В частности, для положительных аргументов
                f(a,b)=a+b, то НГa + НГb &lt;a+b&lt; ВГa + ВГb;
                f(a,b)=a-b, то НГa - ВГb &lt;a-b&lt; ВГa - НГb;
                f(a,b)=a*b, то НГa * НГb &lt;a*b&lt; ВГa * ВГb;
                f(a,b)=a/b, то НГa /ВГb &lt;a/b&lt; ВГa /НГb .
                Расчётная граница метода имеет две строки для вычисления НГ и ВГ выражения.
            </content>
        </topic>
        <topic>
            <name>2. Решение нелинейных уравнений</name>
            <content>
                Лекция 2 Решение нелинейных уравнений.
                1.	Отделение корней.
                2.	Уточнение корня методом поразрядного приближения.
                3.	Метод дихотомии.
                4.	Метод хорд.

                Решением уравнения
                f(х)=0. 	(1)
                называется такое значение х (корень уравнения или нуль функции f(х)), при котором f(х) 0.
                Нелинейные уравнения можно разделить на 2 класса – алгебраические и трансцендентные. Алгебраическими уравнениями называют уравнения, содержащие только алгебраические функции (целые, рациональные, иррациональные). В частности, многочлен является целой алгебраической функцией. Уравнения, содержащие другие функции (тригонометрические, показательные, логарифмические и другие) называются трансцендентными. Методы решения нелинейных уравнений делятся на две группы:
                1)	точные методы;
                2)	итерационные методы.
                Методы нахождения точного значения корней известны только для узкого класса уравнений, например квадратных и биквадратных, некоторых тригонометрических, показательных и логарифмических. На практике чаще встречаются уравнения, которые невозможно решить с помощью элементарных приемов. Кроме того, в расчетах в большинстве случаев нельзя говорить о точном решении уравнений, так как входящие в них коэффициенты заданы приближенно. Поэтому большое значение приобретают методы, позволяющие находить корни уравнения (1.1) с любой наперед заданной степенью точности.
                Задача нахождения приближенного значения корня распадается на два этапа:
                1)	отделение корней;
                2)	уточнение корня.
                Для каждого из этих этапов решения задачи разработаны свои численные методы
                Отделение корней
                Под отделением корня уравнения (1) понимают определение его приближенного значения, либо нахождение какого-либо достаточно узкого отрезка, на котором лежит этот и только этот корень данного уравнения.
                Для отделения корней полезны следующие теоремы из математического анализа.
                Теорема 1. Если функция у=f(х) непрерывна на отрезке [а; b] и f(a)f(b)&lt;0, то внутри отрезка [а; b] существует по крайней мере один корень уравнения (1).
                Теорема 2. Если функция у=f(х) непрерывна на отрезке [а; b], f(a)f(b)&lt;0 и f′(х) на интервале (а; b) сохраняет знак, то внутри отрезка [а; b] существует единственный корень уравнения f(х)=0.
                Для отделения корней можно использовать также график функции у=f(х). Корнями уравнения (1) являются те значения х, при которых график функции у=f(х) пересекает ось абсцисс. Построение графика функции даже с малой точностью обычно дает представление о расположении корней уравнения (1). Если построение графика функции у=f(х) вызывает затруднение, то исходное уравнение (1) следует преобразовать к виду   таким образом, чтобы графики функций  и   были достаточно просты. Абсциссы точек пересечения этих графиков и будут корнями уравнения (1).

                Уточнение корней уравнения
                Если корень уравнения f(х)=0 отделен, т.е. найден отрезок [а; b], на котором имеется один и только один корень уравнения, то любую точку этого отрезка можно принять за приближенное значение корня. Погрешность такого приближения не превосходит длины [а; b]. Следовательно, задача отыскания приближенного значения корня с заданной точностью   сводится к нахождению отрезка [а; b], такого что │b - а│&lt; . Эту задачу обычно называют задачей уточнения корня.
                Итерационный процесс состоит в последовательном уточнении начального приближения х0. Каждый такой шаг называется итерацией. В результате итераций находится последовательность приближенных значений корня х1, х2, ..., хn. Если эти значения с увеличением числа итераций n приближаются к истинному значению корня, то говорят, что итерационный процесс сходится.

                Метод половинного деления
                Разделим отрезок [а; b], содержащий единственный корень, пополам и определим знак функции f(х) в точке х=(а+b)/2. Если f((а+b)/2)=0, тогда корень уравнения найден. Если же f((а+b)/2)≠0, то на концах одного из отрезков [а; (а+b)/2] или [(а+b)/2; b] функция будет принимать значения разных знаков.
                Обозначим этот отрезок через [a1; b1]. Если │b1-a1│&lt; , то любая точка интервала (a1; b1) может быть принята за приближенное значение корня. Если же │b1- a1│≥, то, положив а=а1 , b=b1 и продолжая процесс деления отрезка пополам, на каком-то конечном шаге получим точное значение корня, либо через конечное число шагов длина [a; b]станет меньше . В последнем случае за приближенное значение корня можно принять любую точку отрезка [a; b] (желательно, его середину).
                Метод половинного деления практически удобно применять для грубого нахождения корня данного уравнения, метод прост и надежен, всегда сходится.
                Количество шагов, необходимых для определения корня с точностью , можно рассчитать как


                Метод хорд
                В методе хорд точка пересечения кривой   с осью   на каждом шаге приближается точкой пересечения хорды, стягивающей концы дуги  ,  , с осью  . Последовательные приближения при этом вычисляются по формуле
                .	(2)
                В формуле (2) в качестве   берется тот конец отрезка  , для которого выполняется условие  , а начальное приближение   выбирается так, что  .
                Геометрическая интерпретация метода хорд:

                Описанный метод называется также методом секущих или методом линейной интерполяции. Последовательные приближения в методе хорд образуют монотонную ограниченную сверху или снизу корнем   последовательность. При этом справедлива оценка
                ,
                где  ,  .
                Метод секущих можно рассматривать как метод итерации для эквивалентного уравнения  , где   и начальное приближение берется так, что  .

                2.5 Блок-схемы
                Метод половинного деления





            </content>
        </topic>
        <topic>
            <name>3. Решение нелинейных уравнений (продолжение)</name>
            <content>
                Лекция 3 Решение нелинейных уравнений (продолжение)
                1.	Метод Ньютона.
                2.	Итерационные методы.
                Метод Ньютона
                Уточнение корня методом Ньютона опирается на соотношение
                .                                           (3)
                Начальное приближение в (3) целесообразно выбирать так, чтобы выполнялось условие  .
                Для скорости сходимости метода справедливы оценки
                ,
                ,
                где  ,  . Эти оценки указывают на квадратичную сходимость метода Ньютона.
                Геометрически метод Ньютона означает, что в качестве точек приближения к корню берутся точки пересечения с осью   касательной к кривой  .

                Последовательные приближения сходятся к действительному корню уравнения монотонно со стороны  .

                Комбинированный метод
                Можно заметить, что в качестве начального приближения в методе секущих и касательных берутся противоположные концы отрезка  . Так как последовательные приближения сходятся к корню монотонно, то они всегда определяют отрезок, в котором содержится решение уравнения (1). Будем считать, что  ,   и   сохраняют знак на  . Выбирая в качестве точки   в методе секущих приближения, полученные по методу касательных, придем к формулам комбинированного метода
                ;  .                      (4)
                Геометрическая интерпретация комбинированного метода:

                Метод простой итерации (метод последовательных приближений)
                Заменим уравнение f(х)=0 эквивалентным ему уравнением
                х= (х).	(5)
                Это можно сделать различными способами, например
                х =х + с f'(х), с ≠ 0.
                Пусть известно начальное приближение корня х=х0. Подставляя это значение в правую часть уравнения (5), получим новое приближение:
                х1=(х0).
                Далее, подставляя каждый раз новое значение корня в (5), получаем последовательность значений:
                (6)
                Геометрически метод итерации может быть пояснен следующим образом. Построим на плоскости хОу графики функций у=х и у=(х). Каждый действительный корень   уравнения (4) является абсциссой точки пересечения М кривой у=(х) с прямой у=х (см. рисунок 2 а)).

                Рис.2 Сходящиеся итерационные процессы

                Отправляясь от некоторой точки А0 [x0,  (x0)], строим ломаную А0В1А1В2А2... (“лестница”), звенья которой попеременно параллельны оси Ох и оси Оу, вершины А0,А1,А2,... лежат на кривой у=(х), а вершины В1,В2,В3,…, - на прямой у=х. Общие абсциссы точек А1 и В1, А2 и В2, ..., очевидно, представляют собой соответственно последовательные приближения х1, х2, ... корня  .
                Возможен также другой вид ломаной А0В1А1В2А2 ... – «спираль» (см. рисунок 2 б)). Решение в виде «лестницы» получается, если производная (х) положительна, а решение в виде «спирали», если (х) – отрицательна.

                Рисунок 1. Расходящийся итерационный процесс
                На рисунке а, б кривая у=(х) в окрестности корня   – пологая, то есть  &lt;1, и процесс итерации сходится. Однако, если рассмотреть случай, где  &gt;1, то процесс итерации может быть расходящимся.

                Рис.3. Расходящийся итерационный процесс

                Для практического применения метода итерации нужно выяснить достаточные условия сходимости итерационного процесса.
                Теорема 3. Пусть функция (х) определена и дифференцируема на отрезке [a; b], причем все ее значения (х)[a; b]. Тогда, если существует правильная дробь q такая, что   q&lt; 1 при a &lt; x &lt; b, то:
                1) процесс итерации сходится независимо от начального значения х0  [a, b];

                2) предельное значение   является единственным корнем уравнения х = (х) на отрезке [a; b].

                Скорость сходимости определяется неравенством

                Из этого неравенства, в частности, следует, что скорость сходимости метода простой итерации зависит от величины q: чем меньше q, тем быстрее сходимость. Следовательно, на практике при нахождении корней методом простой итерации желательно представить уравнение f(х)=0 в форме (2) таким образом, чтобы производная  '(х) в окрестности корня по абсолютной величине была возможно меньше. Для этого иногда пользуются параметром с из формулы (3).

                Решение уравнений средствами MathCad
                Найдем нули функции   на интервале x=[–2; 7], используя Mathcad. Изобразим сначала график функции на интервале [–2; 7].


                Рис. 4. График функции   на интервале [–2; 7]
                На заданном интервале функция три раза обращается в ноль. Определим нули функции, используя встроенную функцию root(f(x),x). Первый аргумент – функция, нуль которой необходимо найти, второй – переменная, которую необходимо варьировать. (Вообще говоря, функция f может быть функцией многих переменных и необходимо указывать, по какой именно переменной мы ищем нуль функции.) Кроме того, необходимо задать начальное приближение поиска. Точность вычислений задается встроенной переменной TOL. По умолчанию ее значение равно 0,001. Это значение можно изменить либо через меню Math/Built–In Variables или непосредственно в тексте документа:
                Задаем начальное приближение:
                И вычисляем корень:
                Если требуется найти несколько корней, как в нашей задаче, то имеет смысл определить новую функцию:
                Функция r(x) возвращает значение корня ближайшее к x , то есть начальное приближение мы задаем через аргумент функции. Задаем вектор начальных приближений x и находим соответствующие им корни X:

                Для данного примера корни легко могут быть найдены аналитически. Они равны на заданном интервале /2/2 и 2. Полученный численный результат с заданной точностью совпадает с точным решением.
                Определение новой функции целесообразно и в том случае, когда мы хотим исследовать зависимость решения от параметра. Пусть функция зависит от параметра a

                Первый аргумент функции z задает значение параметра, второй – начальное приближение. Найдем корни уравнения при значениях параметра 1 и 2.

                Если мы хотим получить комплексный корень, то начальное приближение следует задавать комплексным:

                2.4.2 Нахождение корней полиномов
                Для нахождения корней полиномов имеется встроенная функция polyroots(a). Аргументом функции является вектор коэффициентов полинома  , то есть для уравнения  вектор а имеет вид

                Если в полиноме отсутствуют некоторые степени, то на соответствующих местах следует писать 0. Пусть требуется найти корни полинома

                Коэффициенты полинома могут быть и комплексными.

                Нахождение корней уравнений путем символических преобразований
                Во многих случаях, Mathcad позволяет найти аналитическое решение уравнения. Для этого необходимо воспользоваться пунктом Solve for Variable из пункта меню Symbolic. Для того чтобы найти решение уравнения необходимо записать выражение и выделить в нем переменную (поставить указатель курсора возле переменной). Это необходимо для того, чтобы показать, какая именно величина является переменной, а какая – фиксированным параметром. После этого выбираем из пункта меню Symbolic подпункт Solve for Variable
                решение готово ––&gt;
                Обратите внимание! В данном случае был найден только один корень, хотя, очевидно, их бесконечно много.
                В случае полинома Mathcad, а точнее – встроенный символический процессор Maple – находит все корни.
                –&gt;	  	Для этого примера найдено 2 корня, хотя они и вырождены. Пример с комплексными корнями:   ––&gt;

                Поиск корней уравнений в Mathcad
                Mathcad 2000 представляет ряд дополнительных возможностей для поиска корней уравнений. Функция root(f(var1, var2, ...),var1, [a, b]) имеет теперь два необязательных аргумента a и b, которые определяют границы интервала, на котором следует искать корень. На концах интервала [a,b] функция f должна менять знак (f(a)f(b)&lt;0). Задавать начальное приближение для корня не нужно. В данном варианте функция root использует алгоритм Риддера и Брента. Продемонстрируем использование расширенного варианта поиска корней на примере функции

                Для оценки местоположения корней построим график этой функции


                Рис. 5. График функции



                На интервале [1,8] функция имеет два корня. Mathcad 2000 смог найти только один из них.
                Дополнительные возможности появились и для нахождения корней полиномов. Функция polyroots может использовать два различных алгоритма поиска корней – метод Лагерра и метод сопровождающей матрицы. Переключение методов осуществляется в контекстном меню, которое вызывается нажатием правой кнопки мыши, когда указатель установлен на имя функции.


                Метод простой итерации





            </content>
        </topic>
        <topic>
            <name>4. Решение систем уравнений</name>
            <content>
                Лекция 4 Решение систем уравнений
                1.	Системы уравнений.
                2.	Прямые и итерационные методы решения систем линейных алгебраических уравнений (СЛАУ).
                3.	Оценка точности решения СЛАУ.
                4.	Понятие о решения систем нелинейных уравнений.

                Рассмотрим систему т линейных уравнений с п неизвестными:
                (7)
                Система линейных уравнений называется совместной, если она имеет решение, и несовместной, если она не имеет решений.
                Совместная система линейных уравнений называется определенной, если она имеет единственное решение, и неопределенной, если она имеет бесчисленное множество решений.
                Две совместные системы уравнений называются равносильными, если каждое решение первой системы является решением второй и, обратно, каждое решение второй системы является решением первой.
                Следующие преобразования переводят систему уравнений в равносильную ей:
                1) перемена местами двух любых уравнений;
                2) умножение обеих частей любого из уравнений на произвольное число, отличное от нуля;
                3) прибавление к обеим частям одного из уравнений системы соответствующих частей другого уравнения, умноженных на любое действительное число.
                Эти преобразования, по аналогии с элементарными преобразованиями матриц называются элементарными.
                Возможно, что после нескольких таких преобразований в системе появится уравнение, все коэффициенты которого и свободный член равны нулю. Поскольку такому уравнению удовлетворяют любые значения неизвестных, оно может быть отброшено. В этом случае мы получим систему, равносильную данной и содержащую на одно уравнение меньше, чем данная система.
                Если в результате применения элементарных преобразований в системе появляется уравнение, в котором все коэффициенты левой части равны нулю, а свободный член отличен от нуля, то это указывает на то, что уравнение не удовлетворяется никакими значениями неизвестных и, следовательно, полученная система несовместна. Поэтому несовместной является и первоначальная система.
                Методы решения систем уравнений разбиваются на две группы:
                •	точные
                •	приближенные.
                Точными называются такие методы, которые в предположении, что вычисления ведутся точно (без округлений), позволяют в результате выполнения конечного числа арифметических действий получить решение системы. К точным методам относятся, например, методы Крамера, Гаусса, LU-разложения.
                Приближенными называются такие методы, которые даже в предположении, что вычисления ведутся без округлений, позволяют получить решение системы лишь с заданной точностью. Точное решение системы в этих случаях может быть получено теоретически как результат бесконечного процесса. К приближенным методам относятся метод простой итерации и его модификация – метод Зейделя.
                В соответствии с правилом умножения матриц рассмотренная система линейных уравнений (7) может быть записана в матричном виде
                Ах = b,	(7*)
                где    .
                Матрица А, столбцами которой являются коэффициенты при соответствующих неизвестных, а строками – коэффициенты при неизвестных в соответствующем уравнении, называется матрицей системы; матрица-столбец b, элементами которой являются правые части уравнений системы, называется матрицей правой части или просто правой частью системы. Матрица-столбец х, элементы которой - искомые неизвестные, называется решением системы.
                Если матрица А – неособенная, то есть det A  0 то система (7), или эквивалентное ей матричное уравнение (7*), имеет единственное решение.
                В самом деле, при условии det A  0 существует обратная матрица А-1. Умножая обе части уравнения (7*) на матрицу А-1 получим:
                .	(7**)
                Формула (7**) дает решение уравнения (7*) и оно единственно.
                Метод Гаусса для решения систем линейных уравнений (метод последовательного исключения)
                Метод Гаусса заключается в следующем. Допустим, что в системе (7) коэффициент при первом неизвестном a11 0.
                Исключим сначала неизвестное х1 из всех уравнений системы (7), кроме первого. Для этого, прежде всего, разделим обе части первого уравнения на коэффициент a110; тогда получим новую систему, равносильную данной:
                (8)
                Умножим теперь первое уравнение системы (8) на a21 и вычтем из второго уравнения. Затем умножим первое уравнение на a31 и вычтем из третьего уравнения и т.д. В результате получим новую систему, также равносильную данной:
                (9)
                Здесь введены обозначения:
                (10)
                Разделим теперь второе уравнение системы (9) на коэффициент а'22, предполагая, что он отличен от нуля; затем умножим второе уравнение полученной системы последовательно на а'32, ..., а'i2...,..., а'm2 и вычтем поочередно из соответствующих уравнений системы, кроме первого и второго.
                Если, продолжая этот процесс, мы придем к системе, содержащей уравнение, в котором все коэффициенты левой части равны нулю, а свободный член отличен от нуля, то эта система несовместна. В том случае, когда система совместна, приходим либо к системе
                (11)
                (причем р &lt; n), либо к системе
                (12)
                Система вида (11) называется ступенчатой, а система вида (12) — треугольной.
                В случае треугольной системы из последнего уравнения находим xп=βn, затем, подставляя значение xп в предыдущее уравнение, находим xп-т, и т.д.
                Таким образом, если данная система уравнений (7) после выполнения ряда элементарных преобразований приводится к треугольной системе (12), то это означает, что система (7) является совместной и определенной.
                Если же данная система (7) после элементарных преобразований приводится к ступенчатой системе (11), то система (7) совместна и неопределенна.
                Перенося в каждом из уравнений системы (12) члены с неизвестными xp+1,..., xn в правую часть, получим систему вида
                (13)
                Придавая неизвестным xp+1,..., xn ,которые называются свободными, произвольные значения  , получим треугольную систему, из которой последовательно найдем все остальные неизвестные xp, xp-1,..., x1. Так как числа   могут иметь различные значения, то исходная система (3.1) имеет бесчисленное множество решений.
                Процесс нахождения коэффициентов треугольной системы (12) называется прямым ходом, а процесс получения ее решения – обратным ходом метода Гаусса.
                При решении примеров методом Гаусса необходимости выписывать системы нет. Все преобразования можно проводить над матрицами, составленными из коэффициентов этих систем.
                Системе (7) соответствуют две матрицы А и В:
                (14)
                Матрица А называется матрицей системы и состоит из коэффициентов системы, матрица В называется расширенной матрицей и отличается от матрицы системы столбцом, состоящим из свободных членов уравнений системы. При решении системы (7) методом Гаусса элементарные преобразования системы заменяются соответствующими элементарными преобразованиями, выполняемыми над ее расширенной матрицей В.
                В матричной записи это означает, что сначала (прямой ход метода Гаусса) элементарными операциями  над строками приводят расширенную матрицу системы к ступенчатому виду:

                а затем (обратный ход метода Гаусса) эту ступенчатую матрицу преобразуют так, чтобы в первых n столбцах получилась единичная матрица:

                Последний, (n + 1) столбец этой матрицы содержит решение системы.
                Решение СЛАУ методом простой итерации
                Пусть задана система линейных уравнений (5).
                Предполагая, что диагональные коэффициенты aij  0 (i = 1, 2, …, n), разрешим первое уравнение системы (5) относительно х1, второе – относительно х2 и т.д. Тогда получим эквивалентную систему
                (15)
                где   при i  j и  ij = 0 при i = j (i, j = 1, 2, …, n).
                Введя матрицы
                и   ,
                систему (4.2) можно записать в матричной форме
                x=+x,
                а любое (k + 1) приближение вычисляется по формуле
                x(k+1) =+x (k).	(16)
                Напишем формулы приближений в развернутом виде:

                Приведем достаточное условие сходимости метода итераций.
                Теорема 2.1. Процесс итерации для приведенной линейной системы (4.2) сходится к единственному ее решению, если какая-нибудь каноническая норма матрицы  меньше единицы, т.е. для итерационного процесса (2.2) достаточное условие есть
                Следствие 2.1. Процесс итерации для системы (15) сходится, если:
                1)   &lt; 1 (m-норма или неопределенная норма)
                или
                2)   &lt; 1 (l-норма или норма L1)
                или
                3)   &lt; 1 (k-норма или Евклидова норма).
                Следствие 2.2. Для системы (4.1) процесс итерации сходится, если выполнены неравенства:
                1.
                или
                2.	 ,
                где штрих у знака суммы означает, что при суммировании пропускаются значения i=j, т.е. сходимость имеет место, если модули диагональных элементов матрицы А системы (4.1) или для каждой строки превышают сумму модулей недиагональных элементов этой строки, или же для каждого столбца превышают сумму модулей недиагональных элементов этого столбца.
                Таким образом, точное решение системы получается лишь в результате бесконечного процесса, и всякий вектор-столбец x(k) из полученной последовательности является приближенным решением.
                Для системы размерности n n метод итерации сходится, если выполняется неравенство |аij| &gt; |аij| , ij, i=1,..,п, т.е. если модули диагональных коэффициентов для каждого уравнения системы больше суммы модулей всех остальных коэффицнентов (не считая свободных членов).
                Приведение системы (5) к виду (15) можно осуществить различными способами. Важно только, чтобы выполнялось одно из условий Следствия 2.1 и Следствие 2.2. На практике поступают следующим образом: из заданной системы (4.1) выделяют уравнения с коэффициентами, модули которых больше суммы модулей остальных коэффициентов уравнения. Каждое выделенное уравнение выписывают в строку новой системы таким образом, чтобы наибольший по модулю коэффициент оказался диагональным. Из оставшихся неиспользованными и выделенных уравненнй системы составляют линейно независимые линейные комбинации с таким расчетом, чтобы соблюдался указанный выше принцип комплектования новой системы и все свободные строки оказались заполненными. При этом нужно позаботиться, чтобы каждое неиспользованное ранее уравнение попало хотя бы в одну линейную комбинацию, являющуюся уравнением новой системы.
                В качестве условия окончания итерационного процесса можно взять условие
                (4.4)
                 – заданная погрешность приближенного решения х  x(k +1).

                Замечания.
                1. Если итерационный процесс сходится достаточно быстро, т.е. если для решения систем требуется менее п итераций, то получаем выигрыш во времени по сравнению с методом Гаусса, так как число арифметических действий, необходимых для одной итерации, пропорционально п2, а в методе Гаусса – п3.
                2. Погрешность округления в методе итераций сказывается значительно меньше, чем в методе Гаусса. Кроме того, метод итераций является самоисправляющимся, т. е. отдельная ошибка, допущенная в вычислениях, не отражается на окончательном результате, так как ошибочное приближенне можно рассматривать как новый начальный вектор.
                3. Метод простой итерации особенно удобен при решении систем, у которых значительное число коэффициентов равно нулю.
                4. В качестве нулевого приближения Х(0) можно принимать столбец свободных членов.

                Метод Зейделя
                Метод Зейделя представляет собой некоторую модификацию метода итераций. Основная его идея заключается в том, что при вычислении (k + 1)-го приближения неизвестной xi учитываются уже вычисленные ранее (k + 1)-е приближения неизвестных x1, x2, …, xi - 1.
                Пусть получена эквивалентная система (4.2). Выберем произвольно начальные приближения корней  . Далее, предполагая, что k-ые приближения   корней известны, согласно Зейделю будем строить (k + 1)-е приближения корней по формулам:
                (4.5)
                Заметим, что указанные выше условия сходимости для простой итерации остается верной для итерации по методу Зейделя. Обычно метод Зейделя дает лучшую сходимость, чем метод простой итерации, но приводит к более громоздким вычислениям.
                Решение СЛАУ средствами MathCad
                Когда система линейных уравнений невырождена, то есть ее определитель отличен от нуля, более изящным (хотя и не самым эффективным с точки зрения вычислительной математики) является матричный способ решения.
                Решим линейную систему одним и другим методом.



                Решим ту же самую систему матричным методом.
                Запишем матрицу системы и вектор свободных членов.

                Решим систему, умножая слева столбец свободных членов b на матрицу обратную матрице a.

                Если Вы работаете с продвинутой версией Mathcad, то для этих же целей можно воспользоваться встроенной функцией lsolve

                 

                3.3 Блок-схема для метода Гаусса
                 




























                4.3 Блок-схема для метода простой итерации
                Блок-схема Метод простой итерации



            </content>
        </topic>
        <topic>
            <name>5. Приближение функций</name>
            <content>
                Лекция 5 Приближение функций
                1.	Приближение функций.
                2.	Параболическая интерполяция.
                3.	Погрешность интерполирования.

                При решении многих задач анализа и прикладных наук возникает необходимость вместо функции действительного переменного f(x), принадлежащей некоторому широкому классу функций А, рассматривать функцию φ(х), принадлежащую более узкому классу функций В и в известном смысле представляющую функцию f(х) на некотором промежутке. Например, классом А может быть множество непрерывных функций, класс В могут составлять алгебраические или тригонометрические многочлены, которые широко применяются в качестве приближающих функций.
                В утверждение, что функция φ(х) близка к функции f(х) на интервале [а,b], может быть вложен разный смысл. Например,
                1) можно потребовать, чтобы приближающая функция φ(х) совпадала с функцией f(х) в (n+l) точках промежутка, т.е. выполнялись равенства f(xi)=φ(хi) (i=0,1,2, ..., n). Если φ(х) – многочлен степени n, то рассматриваемый процесс приближения называется параболическим интерполированием или процессом построения интерполяционного многочлена;
                2) функцию φ(х) можно выбрать так, чтобы интеграл   или сумма   достигали минимума. Рассматриваемое приближение называется квадратичным;
                3) функцию φ(х) выбирают и так, чтобы maxf(x)—(х) был наименьшим. В этом случае говорят о равномерном приближении функции f(x) функцией (х). В качестве приближающих функций обычно применяются алгебраические и тригонометрические многочлены.
                Интерполяционный многочлен Лагранжа
                Пусть на отрезке [а; b] заданы точки x0, x1, …, xn, которые называются узлами интерполяции. Будем предполагать, что все точки   различны и расположены в порядке возрастания.
                Пусть известны значения некоторой функции  в этих точках:
                .
                Интерполяционный многочлен Ln(x) степени не выше n можно задать формулой Лагранжа
                ,
                где  .
                Разность   называется погрешностью интерполирования или остаточным членом интерполирования. В узлах интерполирования погрешность rn(x) обращается в нуль, в остальных точках она отлична от нуля, но если f(x) – многочлен степени k, а число узлов интерполирования n+1&gt;k, то rn(x)≡0. Если функция f(x) имеет непрерывную n+1-ю производную, то возможно представление остаточного члена вида
                ,
                где ξ – некоторая точка, лежащая на отрезке, содержащем узлы x0, x1, …, xn и точку x.
                Видно, что для данной функции f(x) погрешность интерполирования зависит от выбора узлов x0, x1, …, xn на отрезке [a,b].
                Если принять  , то для подсчёта погрешности метода интерполирования по формуле Лагранжа непосредственно применима следующая оценочная формула
                .
                Многочлен Ньютона.
                Интерполяционная формула Ньютона представляет собой просто другой способ написания интерполяционного многочлена.
                Она полезна, потому что число используемых узлов может быть увеличено или уменьшено без повторения всего вычисления.
                а) Интерполяционная формула Ньютона с неравностоящими узлами:
                Pn(x)=f(x0)+(x-x0)f(x1,x0)+(x-x0)(x-x1)f(x2,x1,x0)+(x-x0)(x-x1)(x-x2)f(x3,x2,x1,x0)+ +…+(x-x0)(x-x1)…(x-xn-1)f(xn,xn-1,…,x1,x0).
                Это формула интерполирования вперед, где используются верхние разности (см. таблицу ниже).
                Разделенные разности могут быть записаны в следующем виде:

                Разделенные разности удобно записывать в виде таблицы.
                Значения аргумента 	Значения функции	Разделенные разности
                первого порядка	второго порядка	третьего
                порядка	четвертого
                порядка
                x0	f(x0)
                f(x1,x0)
                x1	f(x1)		f(x2,x1,x0)
                f(x2,x1)		f(x3,x2,x1,x0)
                x2	f(x2)		f(x3,x2,x1)		f(x4,x3,x2,x1,x0)
                f(x3,x2)		f(x4,x3,x2,x1)
                x3	f(x3)		f(x4,x3,x2)		f(x5,x4,x3,x2,x1)
                f(x4,x3)		f(x5,x4,x3,x2)
                x4	f(x4)		f(x5,x4,x3)
                f(x5,x4)
                x5	f(x5)
                Имеется еще формула Ньютона интерполирования назад.
                Pn(x)=f(xn)+(x-xn)f(xn,xn-1)+(x-xn)(x-xn-1)f(xn,xn-1,xn-2)+(x-xn)(x-xn-1)(x-xn-2)f(xn,xn-1,xn-2,xn-3)+…+(x-xn)(x-xn-1)…(x-x1)f(xn,xn-1,…,x1,x0),
                где используются нижние разности.
                б) Интерполяционная формула Ньютона с равностоящими узлами
                Если ввести шаг интерполяции xk+1-xk=h, то первый интерполяционный многочлен Ньютона можно записать в виде

                Числа y1-y0=y0, y2-y1=y1, y3-y2=y2, ……, yn-yn-1=yn называются разностями первого порядка (первыми разностями) функции f(x). Разности первых разностей называются разностями второго порядка функции y=f(x); они вычисляются по формулам:
                2y0=y1-y0=y2-2y1+y0,
                2y1=y2-y1=y3-2y2+y1,
                ………………………….
                2yn-1=yn-yn-1=yn+1-2yn+yn-1.
                Аналогично определяются разности третьего порядка, четвертого и т.д.
                Разность порядка k определяется формулой
                kyi-1=k-1yi-k-1yi-1 (I=1,2,……, n).
                Разности удобно записывать в виде диагональной таблицы разностей.
                yi	yi	2yi	3yi	4yi	5yi	6yi	7yi
                y0
                y0
                y1		2y0
                y1		3y0
                y2		2y1		4y0
                y2		3y1		5y0
                y3		2y2		4y1		6y0
                y3		3y2		5y1		7y0
                y4		2y3		4y2		6y1
                y4		3y3		5y2
                y5		2y4		4y3
                y5		3y4
                y6		2y5
                y6
                y7
                Для интерполирования назад: xk+1-xk= -h.

                Замечание 1. Если аргумент х, где надо найти приближенное значение функции f(x) находится в начале таблицы, то пользуются формулой Ньютона интерполирования вперед. Если же х в конце, то - формулой интерполирования назад.
                Оценка погрешности приближенного вычисления значений функции, используя формулу остатка:
                |Rn(x)| Mn+1/(n+1)! |ωn+1(x)|  (Mn+1/(n+1)!) max |ωn+1(x)|,
                здесь Mn+1 = max |f(n+1)(x)| на [a,b]
                Замечание 2. При большом числе узлов не удобно пользоваться напрямую многочленами Лагранжа или Ньютона, т.к. получаются слишком высокие степени. Поэтому производят кусочно-полиномиальную интерполяцию: кусочно-линейную, кусочно-квадратичную и так далее. При этом, например, берут попарно узлы [x0,x1], [х1,x2], ..., [xn-1 , xn] для кусочно-линейной интерполяции и на отрезках [хk, xk+1] записывают многочлен Лагранжа по значениям yk,yk+1 - функции. Тогда для x [xk,xk+1] будет f(xk)L(k)1(x), где L(k)1(x) - многочлен Лагранжа, соответствующий отрезку [xk,xk+1]. Погрешность при этом для дважды непрерывно дифференцируемой функции f(x) на [x0,xn] будет |R1(x)|M2/2!|(x-xk)(x-xk+1)|. Если дан шаг h, то отсюда: |R1(x)|  M2/2!∙h2. Задавая погрешность ε, можно получить из неравенства M2/2!∙h2 &lt; ε требуемый шаг h: h &lt;  /M2 для достижения требуемой точности. Аналогично и для кусочно-квадратичной, кусочно-кубичной и т.д. интерполяции.
                Интерполяция сплайнами
                При большом количестве узлов интерполяции возрастает степень интерполяционных многочленов, что делает их неудобными для вычислений.
                В этом случае удобно пользоваться особым видом кусочно-полиномиальной интерполяции – интерполяцией сплайнами.
                Сплайн – это функция, которая на каждом частичном отрезке является алгебраическим многочленом, а на всем заданном отрезке непрерывна вместе с несколькими своими производными. Наиболее распространены на практике сплайны третьей степени (кубические сплайны).
                Пусть интерполируемая функция   задана своими значениями   в узлах
                На отрезке  [ ] функцию   запишем в виде:
                ,
                где   - неизвестные коэффициенты (всего их 4n).
                Используя совпадение значений   в узлах с табличными значениями функции  , получаем следующие уравнения:

                Число этих уравнений – 2n. Для получения дополнительных уравнений используем непрерывность   и   в узлах интерполяции интервала ( ).
                Получаем следующие уравнения:

                Для получения еще двух уравнений используем условие – равенство нулю второй производной  в точках  :

                Исключив   из полученных выше уравнений, получаем систему, содержащую 3n неизвестных:


                Решив данную систему, получаем значения неизвестных  , которые определяют сплайн  .



            </content>
        </topic>
        <topic>
            <name>6. Методы обработки экспериментальных данных</name>
            <content>
                Лекция 6 Методы обработки экспериментальных данных
                1.	Обработка экспериментальных данных.
                2.	Метод наименьших квадратов.
                3.	Регрессия.

                Краткая теория
                1. Постановка задачи
                Пусть в результате измерений в процессе опыта получена таблица некоторой зависимости f:
                x	x1	x2	……	xn
                f(x)	y1	y2	……	yn
                Нужно найти формулу, выражающую эту зависимость аналитически.
                Построение интерполяционных многочленов (например, Лагранжа или Ньютона), нецелесообразно, так как значения функции f в таблице получены в результате измерений и являются сомнительными.
                Практически вид приближающей функции F определяется следующим образом. По таблице строится точечный график функции f, а затем проводится плавная кривая, по возможности наилучшим образом отражающая характер расположения точек. По полученной таким образом кривой устанавливается вид приближающей функции (обычно из числа простых по виду аналитических функций).
                В качестве приближающих функций в зависимости oт характера точечного графика функции f часто используют следующие функции
                1. y=ax+b;
                2. y=ax2+bx+c;
                3. у=ахт;
                4. y=a emx;
                5.  ;
                6. y=a ln x+b;
                7.  ;
                8.  .
                Здесь а, b, с, m – параметры. Когда вид приближающей функции установлен, задача сводится только к отысканию значений параметров.
                Один из распространенных способов нахождения параметров приближающей функции – метод наименьших квадратов - заключается в следующем. Для функции f, заданной таблицей найти функцию y=F(x, a, b, с,…) определенного вида, чтобы сумма квадратов была наименьшей:

                Эта сумма является функцией параметров a, b, с,…. Задача сводится к отысканию минимума этой функции. Используем необходимое условие экстремума функции трех переменных:



                Решив эту систему трех уравнений с тремя неизвестными относительно параметров a, b и с, получим конкретный вид искомой функции F(x,a,b,с). Как видно из рассмотренного примера, изменение количества параметров не приведет к искажению сущности самого подхода, а выразится лишь в изменении количества уравнений в системе.
                Естественно ожидать, что значения найденной функции F(x,а,b,с) в точках х1, х2,..., хп будут отличаться от табличных значений y1, y2,..., yп . Значения разностей
                yi –F(xi, a, b, c)=I (i = 1,2,...,n)
                называются отклонениями (или уклонениями) измеренных значений у от вычисленных. Для найденной эмпирической функции F(x,а,b,с) можно найти сумму квадратов отклонений

                которая для заданного вида приближающей функции (и найденных значений параметров a, b и c) должна быть наименьшей.
                Из двух разных приближений одной и той же табличной функции лучшим является то, для которого сумма  имеет наименьшее значение.
                2. Нахождение приближающей функции
                2.1. Линейная функции
                Будем искать приближающую функцию в виде
                F(x, a, b) = ax + b.
                Частные производные по параметрам а и b:

                Следовательно

                (Сумма Σ здесь и дальше берется по параметру i в пределах 1 до п). Далее имеем:

                Расчет коэффициентов удобно оформлять в виде следующей таблицы:
                x	y	x*y	x2
                x1	y1	x1*y1	x12
                x2	y2	x2*y2	x22
                …	…
                xn	yn	xn*yn	xn2
                Σxi	Σyi	Σ xi*yi	Σ xi2
                Решение системы относительно параметров a и b можно выполнить любым из способов.
                2.2. Квадратный трехчлен. В случае нахождения приближающей функции в виде квадратного трехчлена имеем:
                F(x, а, b, с) = ах2+bх+с.
                Частные производные:
                После несложных преобразований получается система трех линейных уравнении с неизвестными а, b и с. Коэффициенты системы, так же как и в случае линейной функции, выражаются только через известные данные таблицы исходных данных.
                2.3. Другие элементарные функции
                Нахождение приближающей функции с двумя параметрами F(xf a, b) в виде элементарных функций из ранее приведенного списка может быть сведено к нахождению параметров линейной функции.
                2.3.1. Степенная функция
                Предполагая, что в исходной таблице значения аргумента и значения функции положительны, прологарифмируем равенство F(x, a, m)=axm при условии а&gt;0:
                ln F=ln a+m ln x.
                Введем новую переменную u=ln х, тогда ln F будет функцией от u: Ф(u). Обозначая
                m = A, ln a = B
                получим
                Ф(и, A, В)=Аи+В,
                т.е. задача свелась к отысканию приближающей функции в виде линейной.
                Практически для нахождения приближающей функции в виде степенной (при сделанных выше предположениях) необходимо проделать следующее:
                1) по данной таблице (1) вычислить новую таблицу, прологарифмировав значения х и у в исходной таблице;
                2) по новой таблице найти параметры А и В приближающей функции
                3) используя введенные обозначения, найти значения параметров a и m и подставить их в исходное выражение.
                2.3.2 Показательная функция
                Прологарифмируем равенство F(x,a,m)=aexp(mx), a&gt;0:
                ln F=ln a+m*x
                Приняв обозначения, перепишем в виде:
                ln F=Ax+B.
                2.3.3. Дробно-линейная функция
                Равенство   перепишем в виде
                Из последнего равенства следует, что для нахождения значений параметров а и b по заданной таблице нужно составить новую таблицу, у которой значения аргумента оставить прежними, а значения функции заменить обратными числами, после чего для полученной таблицы найти приближающую функцию вида ах+b.
                2.3.4. Логарифмическая функция
                Если приближающая функция имеет вид
                F(x, a, b)=a ln x+b.
                Легко видеть, что для перехода к линейной функции достаточно сделать подстановку ln x=u. Отсюда следует, что для нахождения значений а и b нужно прологарифмировать значения аргумента в исходной таблице и, рассматривая полученные значения в совокупности с исходными значениями функции, найти для полученной таким образом новой таблицы приближающую функцию в виде линейной.
                3.5. Гипербола
                Если точечный график дает ветвь гиперболы, приближающую функцию можно искать в виде

                Для перехода к линейной функции сделаем подстановку и=1/х:
                Ф(u, а, b)=аи + b.
                Практически перед нахождением приближающей функции значения аргумента в исходной таблице следует заменить обратными числами и найти для новой таблицы приближающую функцию в виде линейной
                3.6. Дробно-рациональная функция
                Пусть приближающая функция ищется в виде

                Имеем

                так что задача сводится к случаю, рассмотренному выше.



            </content>
        </topic>
        <topic>
            <name>7. Численное дифференцирование и интегрирование</name>
            <content>
                Лекция 7 Численное дифференцирование и интегрирование
                Дифференцирование и интегрирование.
                Погрешность решения задачи.


                Напомним, что производной функции y=f(x) называется
                (1)
                В случае, когда функция задана таблично, полагают значение Δx=const и для вычисления производной получают приближенное равенство
                (2)
                Это соотношение называется аппроксимацией производной с помощью отношения конечных разностей (значения Δx, Δy в формуле (2) конечные в отличие от их бесконечно малых значений в (1)).
                В зависимости от способа вычисления конечных разностей получаем разные формулы для вычисления производной в одной и той же точке. Найдем выражения для производной y1 при x=x1.
                С помощью левых разностей:
                (3)
                С помощью правых разностей:
                (4)
                С помощью центральных разностей:
                (5)
                Можно найти также выражения для старших производных. Например,
                (6)
                Т.о., по формуле (2) можно найти приближенные значения производных любого порядка. Однако, при этом остается открытым вопрос о точности полученных значений. Кроме того, для хорошей аппроксимации производной нужно использовать значения функции во многих точках, а в формуле (2) это не предусмотрено.
                Использование интерполяционных формул
                Предположим, функция f(x) задана в виде таблицы с постоянным шагом h=xi-xi-1 и интерполируется многочленом Ньютона

                Дифференцируя этот многочлен по переменной x c учетом правила дифференцирования сложной функции:  , получим формулы для вычисления производных любого порядка:


                ……………………………………………………..
                Запишем интерполяционный многочлен Лагранжа и его остаточный член для случая трех узлов интерполяции (n=2) и получим следующие формулы для вычисления производных.


                Здесь y*’’’ – значение производной в некоторой внутренней точке x*[x0, xn].
                Запишем выражение для производной y0’ при x=x0:
                Аналогичные соотношения можно получить и для значений y1’ и y2’ при x=x1  и  x=x2:
                ,       .
                Улучшение аппроксимации
                При рассмотрении конечно-разностных аппроксимаций производных, можно заметить, что порядок точности прямо пропорционален числу узлов, используемых при аппроксимации. Однако с увеличением числа узлов эти соотношения становятся более громоздкими, что приводит к существенному возрастанию объема вычислений. Усложняется также оценка точности получаемых результатов. Вместе с тем существует простой способ уточнения результатов при фиксированном числе узлов, используемых в аппроксимирующих конечно-разностных соотношениях. Это метод Рунге. Пусть
                F(x) – производная, которая подлежит аппроксимации;
                F(x, h) – конечно-разностная аппроксимация этой производной на равномерной сетке с шагом h;
                R – погрешность (остаточный член) аппроксимации, главный член которой можно записать в виде  , т.е.  .
                Тогда выражение для аппроксимации производной в общем случае можно представить виде:
                .
                Эта формула позволяет по результатам двух расчетов значений производной f(x,h) и f(x,kh) с порядком точности p найти ее уточненное значение с порядком p+1.

                Задача численного интегрирования состоит в замене исходной подинтегральной функции f(x), для которой трудно или невозможно записать первообразную, некоторой аппроксимирующей функцией ϕ(x). Такой функцией обычно является полином (кусочный полином)   То есть:   где   – погрешность метода на интервале интегрирования, а r(x) –погрешность метода на отдельном шаге интегрирования.
                Методы вычисления однократных интегралов называются квадратурными (для кратных интегралов – кубатурными). Простейшими являются методы Ньютона-Котеса. Здесь φ(x) – полином различных степеней. Сюда относятся метод прямоугольников, трапеций, Симпсона.
                Метод прямоугольников
                Различают метод левых, правых и средних прямоугольников. Суть метода ясна из рисунка. На каждом шаге интегрирования функция аппроксимируется полиномом нулевой степени – отрезком, параллельным оси абсцисс.

                Выведем формулу метода прямоугольников из анализа разложения функции f(x) в ряд Тейлора вблизи некоторой точки x=xi.

                Рассмотрим диапазон интегрирования от xi до xi+h, где h – шаг интегрирования.
                Вычислим

                Получили формулу правых (или левых) прямоугольников и априорную оценку погрешности r на отдельном шаге интегрирования. Основной критерий, по которому судят о точности алгоритма – степень при величине шага в формуле априорной оценки погрешности.
                В случае равного шага h на всем диапазоне интегрирования общая формула имеет вид

                Здесь n – число разбиений интервала интегрирования,   Для справедливости существования этой оценки необходимо существование непрерывной f'(x).
                Метод средних прямоугольников. Здесь на каждом интервале значение функции считается в точке   то есть   Разложение функции в ряд Тейлора показывает, что в случае средних прямоугольников точность метода существенно выше:

                Метод трапеций.
                Аппроксимация в этом методе осуществляется полиномом первой степени. Суть метода ясна из рисунка.

                На единичном интервале
                В случае равномерной сетки (h=const)   При этом   а   Погрешность метода трапеций в два раза выше, чем у метода средних прямоугольников! Однако на практике найти среднее значение на элементарном интервале можно только у функций, заданных аналитически (а не таблично), поэтому использовать метод средних прямоугольников удается далеко не всегда. В силу разных знаков погрешности в формулах трапеций и средних прямоугольников истинное значение интеграла обычно лежит между двумя этими оценками.
                Особенности поведения погрешности
                Казалось бы, зачем анализировать разные методы интегрирования, если мы можем достичь высокой точности, просто уменьшая величину шага интегрирования. Однако рассмотрим график поведения апостериорной погрешности R результатов численного расчета в зависимости от числа n разбиений интервала (то есть при n→∞ шаг h→0. На участке (1) погрешность уменьшается в связи с уменьшением шага h. Но на участке (2) начинает доминировать вычислительная погрешность, накапливающаяся в результате многочисленных арифметических действий. Таким образом, для каждого метода существует своя Rmin, которая зависит от многих факторов, но прежде всего от априорного значения погрешности метода R.

                Уточняющая формула Ромберга
                Метод Ромберга заключается в последовательном уточнении значения интеграла при кратном увеличении числа разбиений. В качестве базовой может быть взята формула трапеций с равномерным шагом h. Обозначим интеграл с числом разбиений n=1 как   Уменьшив шаг в два раза, получим   Если последовательно уменьшать шаг в 2n раз, получим рекуррентное соотношение для расчета

                Пусть мы вычислили четыре раза интеграл с n от 1 до 4. Представим следующий треугольник:
                R(1;1)
                R(2;1) R(2;2)
                R(3;1) R(3;2) R(3;3)
                R(4;1) R(4;2) R(4;3) R(4;4)
                В первом столбце стоят значения интеграла, полученные при последовательном удвоении числа интервалов. Следующие столбцы – результаты уточнения значения интеграла по следующей рекуррентной формуле:

                Правое нижнее значение в треугольнике – искомое уточненное значение интеграла.
                Метод Симпсона
                Подынтегральная функция f(x) заменяется интерполяционным полиномом второй степени P(x) – параболой, проходящей через три узла, например, как показано на рисунке ((1) – функция, (2) – полином).

                Рассмотрим два шага интегрирования (h=const=xi+1–xi), то есть три узла x0, x1, x2, через которые проведем параболу, воспользовавшись уравнением Ньютона:

                Пусть z=x-x0, тогда

                Теперь, воспользовавшись полученным соотношением, сосчитаем интеграл по данному интервалу:

                В итоге
                Для равномерной сетки и четного числа шагов n формула Симпсона принимает вид:

                Здесь   а   в предположении непрерывности четвертой производной подынтегральной функции.


            </content>
        </topic>
        <topic>
            <name>8. Обыкновенные дифференциальные уравнения</name>
            <content>
                Лекция 8 Обыкновенные дифференциальные уравнения.

                1. 	Постановка задачи.
                Приближённые методы решения обыкновенных дифференциальных уравнений можно разбить на два класса. Одни из них дают приближённое решение в виде аналитического выражения, другие – в виде численных значений. Первую группу методов называют аналитическими, вторую – численными.
                Будем рассматривать здесь применение простейших численных методов. Само собой разумеется, что вопрос об отыскании приближённых значений решения   уравнения
                ,     (1.1)
                удовлетворяющего условию
                (1.2)
                можно ставить, если это решение существует и единственно (т.е. задача корректно поставлена). Как известно, достаточным условием существования и единственности этого решения является непрерывность функции   в рассматриваемой области и ограниченность её частной производной по  . В некоторых случаях условий корректности может оказаться недостаточно. Необходимо, чтобы задача была хорошо обусловлена (устойчива),  т.е.  малые изменения в задании исходных данных приводили к достаточно малым изменениям искомого решения.
                2. 	Метод Эйлера.
                Рассмотрим задачу Коши
                (2.1)
                На отрезке   выберем конечное множество точек

                В методе Эйлера приближённые значения   вычисляются последовательно по формуле
                ,     (2.2)
                где   При этом искомая интегральная кривая  , проходящая через точку  , заменяется ломаной с вершинами в точках  .  Каждое звено ломаной имеет направление, совпадающее с направлением  интегральной кривой (2.1), которая проходит через точку  . Поэтому метод Эйлера часто называют методом ломаных.
                Вычисление приближений   искомого решения   по формуле (2.2) представляет собой обыкновенный метод Эйлера. Этот метод даёт весьма грубое приближенное решения задачи Коши. Он обычно используется в случае, когда необходимо получить примерное представление о решении на небольшом промежутке.
                Если функция   непрерывна и ограничена вместе со своими  первыми производными, т.е.

                для   то имеет место неравенство
                (2.3)
                где
                Метод Эйлера обладает малой точностью, к тому же погрешность каждого нового шага, вообще говоря, систематически возрастает. Наиболее приемлемым для практики методом оценки точности является в данном случае способ двойного счёта – с шагом   и с шагом  . Совпадение десятичных знаков в полученных двумя способами результатах даёт естественные основания считать их верными.

                3. 	Метод Пикара.
                Этот метод позволяет получить приближённое решение дифференциального уравнения (1.1) в виде функции, представленной аналитически. Метод Пикара возник в связи с доказательством теоремы существования и единственности решения уравнения (1.1)  и является, по сути, одним из применений принципа сжимающих отображений.
                В общем случае итерационная формула имеет вид:
                (3.1)
                Циклическое применение формулы (3.1) даёт последовательность функций
                (3.2)
                Так как функция   непрерывна в области  , то она ограничена в некоторой области  , содержащей точку  , т.е.
                (3.3)
                Применяя к уравнению (3.1) в условиях теоремы существования принцип сжимающих отображений, нетрудно показать, что последовательность (3.2) сходится, причём её предел является решением интегрального уравнения (3.1), а следовательно, и дифференциального уравнения (1.1) с начальными условиями (1.2). Это означает, что  й член последовательности (3.2) является приближением к точному решению уравнения (1.1) с определённой степенью точности.
                Оценка погрешности  го приближения даётся формулой:

                где   – константа Липшица,   – верхняя грань модуля функции   из неравенства (3.3), а величина   для определения окрестности   вычисляется по формуле:
                .
                4. 	Метод Рунге-Кутта.
                Рассмотрим задачу Коши на отрезке   для дифференциального уравнения (1.1) с начальным условием (1.2). Будем искать значения приближённого решения этой задачи лишь в фиксированных точках   данного отрезка. Выбранные узловые точки будем считать равноотстоящими:

                Метод Рунге-Кутта – одношаговый метод решения поставленной задачи, т.е. такой метод , который позволяет найти приближённое значение решения заданной задачи в узле   по информации об этом решении лишь в одной предыдущей узловой точке  .
                Рассмотрим метод Рунге-Кутта четвёртого порядка точности, который является одним из самых распространённых методов решения задач с начальными условиями для ОДУ. Итак, пусть дано дифференциальное уравнение (1.1) и условие  , которое либо является начальным условием (при  ), либо получено как результат предыдущего шага. Для получения следующего значения   вначале вычисляются четыре числа:
                (4.1)
                (здесь   – шаг интегрирования). Вслед за этим вычисляется приращение по формуле:

                а потом вычисляется новое значение функции:

                Метод Рунге-Кутта – один из наиболее употребительных методов повышенной точности. Однако общий недостаток методов этого семейства – отсутствие простых способов оценки погрешности метода. Широко используемый на практике для этих методов способ контроля точности – двойной счёт. Если   – вычисленное значение   с шагом  , а   – соответствующее узловое значение, полученное с шагом  , то для ориентировочной оценки погрешности   последнего значения   можно использовать формулу:




            </content>
        </topic>
        <topic>
            <name>9. Системы обыкновенных дифференциальных уравнений</name>
            <content>
                Лекция 9 Системы обыкновенных дифференциальных уравнений.

                Постановка задачи. Пусть имеется система дифференциальных уравнений первого порядка
                (8.1)
                или  ,
                где   – независимый аргумент,   – зависимая функция,  .
                Найти приближенное численное решение системы дифференциальных уравнений – составить таблицу приближенных значений функций  , удовлетворяющих заданным начальным условиям
                ,  .					(8.2)
                Сформулированную задачу решения уравнения (8.1) называют задачей Коши.
                Методы приближенного решения систем дифференциальных уравнений
                Формула	Обозначения
                Метод Эйлера
                ,

                ;
                .
                Модифицированный метод Эйлера
                ,
                ,

                ;
                .
                Метод Рунге-Кутта 4 порядка


                ;
                .

                Постановка задачи. Пусть имеется дифференциальное уравнение высокого ( -го) порядка, разрешенное относительно старшей производной:

                .				(8.1`)
                Найти приближенное численное решение дифференциального уравнения – составить таблицу приближенных значений функций  , удовлетворяющих заданным начальным условиям

                (8.2`)
                Сформулированную задачу решения уравнения (8.1`) называют задачей Коши.

                8.1` Сведение ДУ высокого порядка к системам ОДУ I
                Введем следующие обозначения:
                и
                Теперь решение уравнения (8.1) можно свести к решению системы ОДУ:



            </content>
        </topic>
        <topic>
            <name>10. Решение двухточечных задач методом стрельбы</name>
            <content>
                Лекция 10 Решение двухточечных задач методом стрельбы.

                Отличие краевой задачи от задачи Коши (задачи с начальными условиями) состоит в том, что решение дифференциального уравнения должно удовлетворять граничным условиям, связывающим значения искомой функции более чем в одной точке.
                Простейшим представителем краевой задачи является двухточечная граничная задача, для которой граничные условия задаются в двух точках, как правило, на концах интервала, на котором ищется решение. Двухточечные граничные задачи встречаются во всех областях науки и техники. В случае задания краевых условий в более общем виде использование этих методов не представит принципиальных затруднений.
                1. Пример краевой задачи
                Примером двухточечной краевой задачи является задача:
                y"=f(x,y,y’), a≤x≤b, y(a)=A, y(b)=B	 (1)
                с граничными условиями на обоих концах отрезка, на котором надо найти решение y=y(x). Схематически рассмотрим некоторые способы численного решения краевых задач.
                Если функция f(x,y,y’) в (1) линейна по аргументам y и y’, то мы имеем линейную краевую задачу, иначе — нелинейную краевую задачу.
                2. Линейная краевая задача
                Рассмотрим частную, но довольно распространенную краевую задачу следующего вида:

                (8.2)
                Для этой задачи проиллюстрируем два способа решения: один основан на идее численного построения общего решения линейного дифференциального уравнения, другой (конечно-разностный) сводит исходную дифференциальную краевую задачу к системе линейных алгебраических уравнений, решение которой находится методом прогонки.
                3. Метод численного построения общего решения
                Для нахождения решения краевой задачи (8.2) можно численно построить решение дифференциального уравнения, представимое в виде

                где   — какое-либо решение неоднородного уравнения

                а   и   — два любые линейно независимые решения однородного уравнения   Постоянные   и   находятся из граничных условий задачи (8.2).
                Так как решения       произвольны, то их можно построить различными способами. Например, можно задать какие-то начальные условия и решить одну задачу Коши для неоднородного и две задачи Коши для однородного уравнений. Эти условия, в частности, могут быть такими:
                — для неоднородного уравнения;

                — для однородного уравнения.
                Однако при реализации этого способа, например, в случае   для рассматриваемого уравнения могут возникнуть трудности, связанные с неустойчивостью задачи Коши. В этом случае можно попытаться построить       с помощью решения одной краевой задачи для неоднородного уравнения и двух краевых задач для однородного уравнения. Краевые условия для этих задач могут быть, например, следующими:
                — для неоднородного уравнения;

                — для однородного уравнения.
                Эти задачи могут быть решены методом прогонки. Условия устойчивости метода прогонки при   как легко проверить, выполнены. Этот подход может оказаться полезным, если краевые условия таковы, что для исходной задачи (8.2) метод прогонки применен быть не может.
                Отметим, что с учетом специфики краевых условий исходной задачи можно строить общее решение вида

                где   — некоторое решение неоднородного уравнения, а   — некоторое решение однородного уравнения.
                2.4. Конечно-разностный метод (метод прогонки)
                При нахождении решения линейной краевой задачи:


                для   методом построения общего решения, если оно находится с помощью решения задач Коши, могут возникнуть трудности, связанные с вычислительной неустойчивостью задачи Коши.
                Для решения поставленной задачи можно воспользоваться разностной схемой:


                и решить разностную задачу методом прогонки. Условия применимости метода прогонки при   как легко проверить, выполнены. Подробнее о методе прогонки см. в [1–4, 17, 31]. В [17] рассмотрены различные варианты метода прогонки.
                2.5. Нелинейная краевая задача
                Краевая задача

                (8.3)
                является нелинейной краевой задачей, если функция   нелинейна хотя бы по одному из аргументов y или
                В настоящей работе реализованы два способа решения нелинейных краевых задач: метод стрельбы и метод линеаризации (метод Ньютона), который сводит решение нелинейной краевой задачи к решению серии линейных краевых задач.
                2.6. Метод стрельбы
                Метод стрельбы для решения краевой задачи (8.3) базируется на том, что имеются удобные способы численного решения задачи Коши, т. е. задачи следующего вида

                (4)

                где   — ордината точки   из которой выходит интегральная кривая; a — угол наклона интегральной кривой к оси x при выходе из точки   (рис. 8). При фиксированном   решение задачи (8.4) имеет вид   При   решение   зависит только от a:

                Используя указанное замечание о решении задачи Коши (8.4), можно задачу (8.3) переформулировать следующим образом: найти такой угол   при котором интегральная кривая, выходящая из точки   под углом a к оси абсцисс, попадет в точку
                (5)
                Решение задачи (8.4) при этом   совпадает с искомым решением задачи (8.3). Таким образом, дело сводится к решению уравнения (8.5) (рис. 9). Уравнение (5) — это уравнение вида

                где
                Оно отличается от привычных уравнений лишь тем, что функция   задана не аналитическим выражением, а с помощью алгоритма численного решения задачи (8.4).
                Для решения уравнения (8.5) можно использовать любой метод, пригодный для уточнения корней нелинейного уравнения, например, метод деления отрезка пополам, метод Ньютона (касательных) и др. Метод Ньютона здесь предпочтительнее (если имеется достаточно хорошее начальное приближение) из-за высокой стоимости вычисления одного значения функции F(a) (нужно решить задачу Коши (8.4) с данным a).
                Метод стрельбы, сводящий решение краевой задачи (8.3) к вычислению решений задачи Коши (8.4), хорошо работает в том случае, если решение   «не слишком сильно» зависит от a. В противном случае он становится вычислительно неустойчивым, даже если решение задачи (8.3) зависит от входных данных «умеренно».
                При решении уравнений   методом деления отрезка пополам, мы задаем   и   так, чтобы разности   и   имели разные знаки. Затем полагаем

                Вычисляем   Затем вычисляем   по одной из формул:
                или
                в зависимости от того, имеют ли разности   и   соответственно разные или одинаковые знаки. Затем вычисляем   Процесс продолжаем до тех пор, пока не будет достигнута требуемая точность
                В случае использования для решения уравнения   метода Ньютона задаем   а затем последующие   вычисляем по рекуррентной формуле
                n = 0, 1, …
                Производная   может быть вычислена по одной из формул численного дифференцирования, например, первого порядка аппроксимации:

                2.7. Вычислительная неустойчивость задачи Коши
                Поясним причину возникновения вычислительной неустойчивости на примере следующей линейной краевой задачи:

                (8.6)
                при постоянном   Выпишем решение этой задачи:

                Коэффициенты при   и   с ростом р остаются ограниченными на отрезке   функциями; при всех   они не превосходят единицу. Поэтому небольшие ошибки при задании   и   ведут к столь же небольшим погрешностям в решении, т. е. краевая задача является «хорошей».
                Рассмотрим теперь задачу Коши:

                (8.7)
                Ее решение имеет вид:

                Если при задании   допущена погрешность e, то значение решения при   получит приращение
                (8.8)
                При больших р вычитаемое в равенстве (8.8) пренебрежимо мало, но коэффициент в первом слагаемом   становится большим. Поэтому метод стрельбы при решении задачи (8.6), будучи формально приемлемой процедурой, при больших р становится практически непригодным. Подробнее о возникновении неустойчивостей см. [1, 2].
                2.8. Метод линеаризации (метод Ньютона)
                Метод Ньютона сводит решение нелинейной краевой задачи к решению серии линейных краевых задач и состоит в следующем.
                Пусть для нелинейной краевой задачи (8.3) известна функция  удовлетворяющая граничным условиям и грубо приближенно равная искомому   Положим
                (8.9)
                где   — поправка к нулевому приближению   Подставим (8.9) в уравнение (8.8) и линеаризуем задачу, используя следующие равенства:


                Отбрасывая остаточный член   получим линейную краевую задачу для нахождения поправки

                (8.10)
                где


                Решая линейную краевую задачу (8.10) каким-либо численным методом, найдем поправку   и примем за первое приближение

                Аналогично, зная приближение   положим   и найдем следующее приближение. Продолжая процесс до тех пор, пока не будут выполнены неравенства

                где e — требуемая точность, найдем приближенное решение исходной нелинейной задачи.



            </content>
        </topic>
        <topic>
            <name>11. Реализация вычислительных методов в электронных таблицах, системах компьютерной математики, системах программирования</name>
            <content>
                Лекция 11 Реализация вычислительных методов в электронных таблицах, системах компьютерной математики, системах программирования.



            </content>
        </topic>
    </section>
    <section val="2" name="Компьютерное моделирование">
        <topic>
            <name>12. Математическое моделирование. Исследование операций</name>
            <content>
                Лекция 12 Математическое моделирование. Исследование операций.



            </content>
        </topic>
        <topic>
            <name>13. Задачи оптимизации. Методы визуализации</name>
            <content>
                Лекция 13 Задачи оптимизации. Методы визуализации.

                1.1	О  численных методах многомерной оптимизации.

                Задача многомерной безусловной оптимизации формулируется в виде:
                min f(x),
                xX
                где x={x(1), x(2),…, x(n)} – точка в n-мерном пространстве X=IRn, то есть целевая функция f(x)=f(x(1),…,f(x(n)) – функция n аргументов.
                Так же как и в первой лабораторной работе мы рассматриваем задачу минимизации. Численные методы отыскания минимума, как правило, состоят в построении последовательности точек {xk}, удовлетворяющих условию f(x0)&gt;f(x1)&gt;…&gt;f(xn)&gt;… . Методы построения таких последовательностей называются методами спуска. В этих методах точки последовательности {xk} вычисляются по формуле:
                хk+1 = xk + kpk, k=0,1,2,… ,
                где pk – направление спуска, k – длина шага в этом направлении.
                Различные методы спуска отличаются друг от друга способами выбора направления спуска pk и длины шага k вдоль этого направления. Алгоритмы безусловной минимизации принято делить на классы, в зависимости от максимального порядка производных минимизируемой функции, вычисление которых предполагается. Так, методы, использующие только значения самой целевой функции, относят к методам нулевого порядка (иногда их называют также методами прямого поиска); если, кроме того, требуется вычисление первых производных минимизируемой функции, то мы имеем дело с методами первого порядка; если же дополнительно используются вторые производные, то это методы второго порядка и т.д.

                1.2. Градиентные методы.
                1.2.1. Общая схема градиентного спуска.
                Как известно, градиент функции в некоторой точке xk направлен в сторону наискорейшего локального возрастания функции и перпендикулярен линии уровня (поверхность постоянного значения функции f(x), проходящей через точку xk). Вектор, противоположный градиенту  , называется антиградиентом, который направлен в сторону наискорейшего убывания функции f(x). Выбирая в качестве направления спуска pk антиградиент -  в точке xk, мы приходим к итерационному процессу вида:
                xk+1 = xk - k f’(xk), k&gt;0, k=0,1,2,… .
                В координатной форме этот процесс записывается следующим образом:
                Все итерационные процессы, в которых направление движения на каждом шаге совпадает с антиградиентом функции, называются градиентными методами. Они отличаются друг от друга только способом выбора шага k. Существует много различных способов выбора k, но наиболее распространены: метод с постоянным шагом, метод с дроблением шага и метод наискорейшего спуска.

                1.2.2. Градиентный метод с постоянным шагом.
                Основная проблема в градиентных методах – это выбор шага k. Достаточно малый шаг k обеспечивает убывание функции, то есть выполнение неравенства:
                f(xk - k ( xk))) &lt; f(xk),
                но может привести к неприемлемо большому количеству итераций, необходимых для достижения точки минимума. С другой стороны, слишком большой шаг может вызвать неожиданный рост функции (невыполнение условия убывания) либо привести к колебаниям около точки минимума. Однако проверка условия убывания на каждой итерации является довольно трудоемкой, поэтому в методе градиентного спуска с постоянным шагом задают =k постоянным и достаточно малым, чтобы можно было использовать этот шаг на любой итерации. При этом приходится мириться с возможно большим количеством итераций. Утешением является лишь то, что трудоемкость каждой итерации, в этом случае, минимальна (нужно вычислять только градиент  ).

                Схема алгоритма
                Шаг 1. Задаются начальное приближение х0, постоянный шаг , условия останова алгоритма 3. Вычисляется значение градиента   – направление поиска. Присваивается к=0.
                Шаг 2. Определяется точка очередного эксперимента:
                хк+1 = хk - f’(xk),
                или, в координатной форме:
                Шаг 3. Вычисляется значение градиента в точке хк+1:
                ,
                или, в координатной форме:
                Шаг 4. Если || ||3, то поиск заканчивается, при этом:
                Иначе k=k+1 и переходим к шагу 2.

                1.2.3. Градиентный метод с дроблением шага.
                В методе градиентного спуска с дроблением шага величина шага к выбирается так, чтобы было выполнено неравенство:
                f(xk-k )-f(xk)-k|| ||2,
                где 0&lt;&lt;1 – произвольно выбранная постоянная (одна и та же для всех итераций). Это требование на выбор шага к более жесткое, чем условие убывания, но имеет тот же смысл: функция должна убывать от итерации к итерации. Однако при выполнении неравенства функция будет уменьшаться на гарантированную величину, определяемую правой частью неравенства.
                Процесс выбора шага протекает следующим образом. Выбираем число &gt;0, одно и то же для всех итераций. На к-й итерации проверяем выполнение неравенства при к=. Если оно выполнено, полагаем к= и переходим к следующей итерации. Если нет, то шаг к дробим, например, уменьшаем каждый раз в два раза, до тех пор, пока оно не выполнится.

                Схема алгоритма
                Шаг 1. Задаются х0, 3,  и начальное значение шага . Вычисляется значение градиента   – направление поиска. Присваивается к=0.
                Шаг 2. Проверяется условие: f(xk- )-|| ||2. Если выполняется, то переходим к шагу 3, иначе дробим значение  (=/2) и повторяем шаг 2.
                Шаг 3. Определяется точка очередного эксперимента: хк+1 = хк -  .
                Шаг 4. Вычисляется значение градиента в точке хк+1:  .
                Шаг 5. Если || ||3, то поиск заканчивается, при этом:
                Иначе к=к+1 и переходим к шагу 2.

                1.2.4. Метод наискорейшего спуска.
                В градиентном методе с постоянным шагом величина шага, обеспечивающая убывание функции f(x) от итерации к итерации, оказывается очень малой, что приводит к необходимости проводить большое количество итерации для достижения точки минимума. Поэтому методы спуска с переменным шагом являются более экономными. Алгоритм, на каждой итерации которого шаг к выбирается из условия минимума функции f(x) в направлении движения, то есть:
                называется методом наискорейшего спуска. Разумеется, этот способ выбора к сложнее ранее рассмотренных вариантов.
                Реализация метода наискорейшего спуска предполагает решение на каждой итерации довольно трудоемкой вспомогательной задачи одномерной минимизации. Как правило, метод наискорейшего спуска, тем не менее, дает выигрыш в числе машинных операций, поскольку обеспечивает движение с самым выгодным шагом, ибо решение задачи одномерной минимизации связано с дополнительными вычислениями только самой функции f(x), тогда как основное машинное время тратится на вычисление ее градиента  .
                Следует иметь в виду, что одномерную минимизацию можно производить любым методом одномерной оптимизации, что порождает различные варианты метода наискорейшего спуска.

                Схема алгоритма
                Шаг 1. Задаются х0, 3. Вычисляется градиент  , направление поиска. Присваивается k=0.
                Шаг 2. Определяется точка очередного эксперимента:
                хк+1 = хк - к ,
                где к – минимум задачи одномерной минимизации:
                Шаг 3. Вычисляется значение градиента в точке хк+1:  .
                Шаг 4. Если || ||3, то поиск точки минимума заканчивается и полагается:
                Иначе к=к+1 и переход к шагу 2.

                1.3.Метод покоординатного спуска.
                Желание уменьшить объем вычислительной работы, требуемой для осуществления одной итерации метода наискорейшего спуска, привело к созданию методов покоординатного спуска.
                Пусть 	 - начальное приближение. Вычислим частную производную по первой координате и примем:
                где е1={1,0,…,0}T – единичный вектор оси х(1). Следующая итерация состоит в вычислении точки х2 по формуле:
                где е2={0,1,0,…,0}T – единичный вектор оси х(2) и т. д.
                Таким образом, в методах координатного спуска мы спускаемся по ломанной, состоящей из отрезков прямых, параллельных координатным осям.

                Спуск по всем координатам составляет одну «внешнюю» итерацию. Пусть к – номер очередной внешней итерации, а j – номер той координаты, по которой производится спуск. Тогда формула, определяющая следующее приближение к точке минимума, имеет вид:
                где к=0,1,2,… ;  j=1,2,…n.
                В координатной форме формула выглядит так:
                После j=n счетчик числа внешних итераций к увеличивается на единицу, а j принимает значение равное единице.
                Величина шага к выбирается на каждой итерации аналогично тому, как это делается в градиентных методах. Например, если к= постоянно, то имеем покоординатный спуск с постоянным шагом.

                Схема алгоритма покоординатного спуска с постоянным шагом
                Шаг 1. При к=0 вводятся исходные данные х0, 1, .
                Шаг 2. Осуществляется циклический по j (j=1,2,…,n) покоординатный спуск из точки хkn по формуле:
                Шаг 3. Если ||x(k+1)n – xkn||1, то поиск минимума заканчивается, причем:
                Иначе k=k+1 и переходим к шагу 2.
                Если же шаг к выбирается из условия минимума функции:
                то мы получаем аналог метода наискорейшего спуска, называемый обычно методом Гаусса – Зейделя.

                Схема метода Гаусса – Зейделя
                Шаг 1. При к=0 вводятся исходные данные х0, 1.
                Шаг 2. Осуществляется циклический по j (j=1,2,…,n) покоординатный спуск из  точки хkn по формулам:
                где kn+j-1 является решением задачи одномерной минимизации функции:
                Шаг 3. Если ||x(k+1)n – xkn||1, то поиск минимума заканчивается, причем:
                Иначе к=к+1 и переходим к шагу 2.

                1.4. Методы оврагов

                1.4.1. Общая характеристика.
                Градиентные методы медленно сходятся в тех случаях, когда поверхности уровня целевой функции f(x) сильно вытянуты. Этот факт известен в литературе как «эффект оврагов». Суть эффекта в том, что небольшие изменения одних переменных приводят к резкому изменению значений функции – эта группа переменных характеризует «склон оврага», а по остальным переменным, задающим направление «дно оврага», функция меняется незначительно. На рисунке изображены линии уровня «овражной» функции траектория градиентного метода характеризуется довольно быстрым спуском на «дно оврага», и затем медленным зигзагообразным движением в точку минимума.

                Существуют различные подходы для определения точки минимума функции f(x) в овражной ситуации. Большинство из них основаны на эвристических (то есть интуитивных, не обоснованных строго) соображениях. Их можно применять в ситуациях, когда применение более совершенных методов невозможно или нецелесообразно, например, значение целевой функции вычисляется со значительными погрешностями, информация о ее свойствах недостаточна, и т. д. Эти методы просты в реализации и довольно часто применяются на практике, позволяя в ряде случаев получить удовлетворительное решение задачи.

                1.4.2. Эвристические алгоритмы.
                Иногда, используя градиентный спуск для минимизации функций со сложной топографической структурой, применяют эвристические схемы, которые идейно близки к методам спуска. Мы рассмотрим две такие схемы.
                Первая эвристическая схема содержит два основных этапа. Оба этапа представляют собой аналоги градиентного спуска с постоянным шагом. Только вместо градиента   используется вектор g(x), формируемый из координат  , но на каждом из этапов по разным правилам.
                На первом этапе задается малое число 1&lt;&lt;1 и используется градиентный спуск, где вместо градиента   берется вектор g(x)={g(1)(x),…,g(n)(x)}, который определяется следующим образом:

                Таким образом, спуск производится лишь по тем переменным, в направлении которых производная целевой функции достаточно велика. Это позволяет быстро спуститься на «дно оврага». Мы спускаемся до тех пор, пока метод не зациклится, то есть до тех пор, пока каждая следующая итерация позволяет найти точку, в которой значение функции меньше, чем значение, найденное в предыдущей итерации. После этого переходим к следующему этапу.
                На втором этапе задается некоторое большое число 2&gt;&gt;1 и используется процедура спуска, где вместо градиента   берется вектор g(x)={g(1)(x),…,g(n)(x)}, который определяется следующим образом:

                В этом случае перемещение происходит по «берегу» оврага вдоль его «дна». Как и на первом этапе, спуск продолжается до тех пор, пока метод не зациклится.
                После выполнения первого и второго этапов принимается решение о завершении работы или продолжении. Для этого сравнивается норма разности предыдущей точки, то есть точки, которую мы имели до применения первого и второго этапов, с текущей точкой, то есть полученной после применения с точностью решения задачи 1. Если эта норма меньше 1 и норма градиента в текущей точке меньше 3, то поиск заканчивается и последняя вычисленная точка принимается за приближенное решение задачи. Иначе для текущей точки вновь повторяем первый и второй этапы и т. д.

                Схема алгоритма
                Шаг 1. Задаются х0, 1, 3,1,2,1 – постоянный шаг пункта 1 и 2 – постоянный шаг пункта 2 (1&lt;2). Присваивается k=0.
                Шаг 2. (Первый этап). Из точки хк осуществляется спуск на «дно оврага» с постоянным шагом 1. При спуске вычисление очередной точки осуществляется с использованием формул:
                xj+1 = xj - 1g(xj), где  g(x)={g(1)(x),…,g(n)(x)},
                Пусть этот процесс остановится в точке xl.
                Шаг 3. (Второй этап). Из точки xl осуществляется спуск вдоль «дна оврага» с постоянным шагом 2. При спуске используются формулы: xj+1 = xj - 2g(xj), где
                g(x)={g(1)(x),…,g(n)(x)},
                Пусть этот процесс остановился в точке xm.
                Шаг 4. Если ||xk – xm||  1 и || ||  3, то полагаем:
                и поиск минимума заканчивается.
                Иначе k=m и переходим к шагу 2.

                1.4.3. Овражные методы (Метод Гельфанда).
                Вторая эвристическая схема, предложенная И.М. Гельфандом, состоит в следующем.
                Пусть х0 и      - две произвольные близкие точки. Из х0 совершают обычный градиентный спуск с постоянным шагом и после нескольких итераций с малым шагом  попадем в точку u0. Тоже самое делаем для точки     , получая точку     . Две точки u,     лежат в окрестности «дна оврага». Соединяя их прямой, делаем «большой шаг»  в полученном направлении, перемещаясь «вдоль дна оврага» (шаг  называют овражным шагом). В результате получаем точку х1. В ее окрестности выбираем точку        и повторяем процедуру.








                Схема овражного метода 1.
                Шаг 1. Вводятся начальное приближение х0, точность решения 1 и 3, шаг  для градиентного спуска, начальное значение  для овражного шага. Из точки х0 осуществляется градиентный спуск с постоянным шагом  на дно оврага. В результате получается точка u0. Полагается k=0.
                Шаг 2. В окрестности хк берется точка и из нее осуществляется градиентный спуск. В результате получается точка      .
                Шаг 3. Новая точка хк+1 определяется следующим образом. По формуле
                или
                вычисляется точка x'k+1. Из нее осуществляется градиентный спуск и мы получаем точку  . Если f( )&lt;f(uk), то полагаем xk+1=  и uk+1= .
                Иначе уменьшаем овражный шаг  (например в 2 раза =/2) и повторяем шаг 3.
                Шаг 4. Если ||uk+1-uk||1 и || ||3, то полагаем:
                и поиск минимума на этом заканчивается, иначе к=к+1 и переходим к шагу 2.
                Рассмотрим другую реализацию той же идеи.
                Пусть х0 и х1 – две произвольные близкие точки. Как и в предыдущем случае, из каждой точки осуществим градиентные спуски с постоянным шагом . Получим точки u0 и u1, лежащие в окрестности «дна оврага». Соединяя их прямой, делаем «большой шаг»  в полученном направлении. В результате получим точку х2. Из этой точки осуществим градиентный спуск и получим точку u2. А вот далее, для того чтобы осуществить «овражный шаг», берем предпоследнюю точку u1. Соединяя прямой точки u2 и u1, делаем шаг  в полученном направлении и определяем х3. Дальше аналогичным образом вычисляются х4,х5, … .

                Схема овражного метода 2

                Шаг 1. Задаются начальное приближение х0, точность решения 1 и 3, шаг  для градиентного спуска, начальное значение  для овражного шага.
                Из точки х0 осуществляется градиентный спуск с постоянным шагом  на «дно оврага». В результате получается точка u’0.
                В окрестности х0 берется точка х1, из которой тоже осуществляется градиентный спуск на «дно оврага». В результате получается точка u’1. Полагается к=1. Если f(u’0)&lt;f(u’1), то полагаем u0=u’1, u1=u’0. Если f(u’0)&gt;f(u’1), то u0=u’0, u1=u’1.
                Шаг 2. Новая точка хк+1 определяется следующим образом. По формуле:
                вычисляется точка x'k+1. Из нее осуществляется градиентный спуск и мы получаем точку  . Если f( )&lt;f(uk), то полагаем xk+1=  и uk+1= . Иначе уменьшаем овражный шаг  (например в 2 раза =/2)и повторяем шаг 2.
                Шаг 3. Если ||uk+1-uk||1 и || ||3, то полагаем:
                и поиск минимума на этом заканчивается, иначе к=к+1 и переходим к шагу 2.

                1.5. Методы прямого поиска.

                1.5.1. Общая характеристика.
                Методы прямого поиска – это методы, в которых используются только значения целевой функции (методы нулевого порядка). Рассмотрим следующие методы, основанные на эвристических соображениях. Эти методы довольно часто применяются на практике, позволяя в ряде случаев получить удовлетворительные решения.
                Основное достоинство методов нулевого порядка состоит в том, что они не требуют непрерывности целевой функции и существования производных.

                1.5.2. Метод конфигураций (метод Хука и Дживса).
                Алгоритм включает в себя два основных этапа поиска.
                а) В начале обследуется окрестность выбранной точки (базисной точки), в результате находится приемлемое направление спуска;
                б) Затем в этом направлении находится точка с наименьшим значением целевой функции. Таким образом находится новая базисная точка.
                Эта процедура продолжается пока в окрестностях базисных точек удается находить приемлемые направления спуска.

                Схема алгоритма
                Шаг 1. Задаются начальное приближение (первая базисная точка)
                начальный шаг h для поиска направления спуска, точность решения (предельное значение для шага h). Присваивается k=0.
                Шаг 2. (Первый этап). Определяется направление минимизации целевой функции f(x)=f(x(1),x(2),…,x(n)) в базисной точке	. Для этого последовательно дают приращение переменным x(j) в точке хк. Присвоим z=xk. Циклически даем приращение переменным x(j) и формируем z(j)=xk(j)+h, если f(z)&lt;f(xk), если же нет, то z(j)=xk(j)-h, если f(z)&lt;f(xk), иначе z(j)=xk(j). Так для всех j(j=1,2,…,n).
                Шаг 3. Если z=xk, то есть не определилось подходящее направление, то обследование окрестности базисной точки хк повторяется, но с меньшим шагом h (например, h=h/2).
                Если h&gt;, то перейти к шагу 2, то есть повторить обследование точки хк.
                Если h, то поиск заканчивается, то есть достигнуто предельное значение для шага h и найти приемлемое направление спуска не удается. В этом случае полагается

                Шаг 4. (Второй этап). Если zxk, то требуется найти новую базисную точку в направлении вектора z-xk: xk+1=xk + (z-xk), где  - коэффициент «ускорения поиска».
                Определяется такое значение =к, при котором достигается наименьшее значение целевой функции в выбранном направлении, то есть функции              f(xk +(z-xk) = ().
                В зависимости от способа выбора к возможны варианты метода:
                а) к==const постоянная для всех итераций;
                б) задается начальное 0=, а далее к=к-1, если f(xk+1)&lt;f(xk), иначе дробим к, пока не выполнится это условие;
                в) к определяется решением задачи одномерной минимизации функции ().
                Таким образом определяется новая базисная точка xk+1=xk + (z-xk). Полагаем к=к+1 и поиск оптимального решения повторяется с шага 2.
                1.5.3.Метод симплекса.
                Под симплексом понимается n-мерный выпуклый многогранник n-мерного пространства, имеющий n+1 вершину. Для n=2 это треугольник, а при n=3 это тетраэдр.
                Идея метода состоит в сравнении значений функции в n+1 вершинах симплекса и перемещении симплекса в направлении лучшей точки. В рассматриваемом методе симплекс перемещается с помощью операций отражения. Далее принято следующее: х0(k), х1(k), … , хn(k) – вершины симплекса, где к - номер итерации.
                Схема алгоритма
                Шаг 1. Построение начального симплекса. Для этого задаются начальная точка х0(0) и длина ребра симплекса l. Формируются остальные вершины симплекса:
                xi(0) = x0(0) + l*ei (i=1,2,…,n), где ei – единичные векторы.











                Шаг 2. Определение направления улучшения решения. Для этого на к-й итерации вычисляются значения целевой функции в каждой точке симплекса. Пусть для всех i:
                f(xmin(k))f(xi(k))f(xmax(k)),
                где min, max, i – номера соответствующих вершин симплекса. Определим центр тяжести всех точек, исключая точку xmax(k),
                Ck=(xi(k))/n .
                Тогда направление улучшения решения определяется вектором Ck-xmax(k).
                Шаг 3. Построение отраженной точки. Замена вершины xmax(k) с максимальным значением целевой функции на новую точку с помощью операции отражения, результатом которой является новая точка:
                uk=ck+(ck-xmax(k))=2ck-xmax(k)
                x(2)
                Шаг 4. Построение нового симплекса. Вычисляем f(uk). При этом возможен один из двух случаев:
                а) f(uk)&lt;f(xmax(k);
                б) f(uk)f(xmax(k).
                Случай а): вершина xmax заменяется на uk, чем определяется набор вершин к+1-й итерации и к-я итерация заканчивается.
                Случай б): в результате отражения получается новая точка uk, значение функции в которой еще хуже, чем в точке xmax, то есть отражать симплекс некуда. Поэтому в этом случае производится пропорциональное уменьшение симплекса (например, в 2 раза) в сторону вершины xmin(k):
                xi(k+1)=x^i=(xi(k)+xmin(k))/2, где i=0,1,…,n.
                На этом к-я итерация заканчивается.
                Шаг 5. Проверка сходимости. Если
                то поиск минимума заканчивается и полагается
                В противном случае k=k+1 и происходит переход к шагу 2.

                1.5.4. Метод деформируемого симплекса (метод Нелдера – Мида).
                Метод деформируемого симплекса обладает большей общностью и позволяет учитывать локальные свойства поверхности целевой функции. Симплексы вытягиваются в направлении наклона поверхности, их оси поворачиваются при встрече с оврагом на поверхности целевой функции, вблизи минимума они сжимаются.
                В рассматриваемом методе симплекс перемещается с помощью трех основных операций над симплексом: отражение, растяжение и сжатие.
                Схема алгоритма.
                Шаг 1. Построение начального симплекса. Задаются начальная точка х0(0) и длина ребра l. Формируются остальные вершины симплекса:  xi(0)=x0(0)+lei (i=1,2,…,n), где ei – единичные векторы.
                Шаг 2. Определение направления улучшения решения. Для этого на каждой итерации вычисляются значения целевой функции в каждой вершине симплекса. Пусть для всех i
                f(xmin(k))  f(xi(k))   f(xm(k))   f(xmax(k)),
                где min, m, max, i-номера соответствующих вершин симплекса. Определим центр тяжести всех точек, исключая точку xmax(k),

                Тогда направление улучшения решения определяется векторов
                Ck- xmax(k).
                Шаг 3. Построение нового симплекса. Замена вершины xmax(k) с максимальным значением целевой функции на новую точку с помощью операции отражения, результат которой является новая точка
                uk=Ck+*(Ck-xmax(k)),   где -коэффициент отражения.
                Шаг 4. Построение нового симплекса. Вычисляем f(uk), при этом возможно один из трех случаев:
                а)  f(uk)&lt; f(xmin(k));
                б)  f(uk)&gt;f(xm(k));
                в)  f(xmin(k))  f(uk)   f(xm(k));
                Случай а): отражённая точка является точкой с наилучшим значением целевой функции. Поэтому направление отражение является перспективным и можно попытаться растянуть симплекс в этом направлении. Для этого строиться точка
                Vk= Ck+*(uk-Ck),  где &gt;1 –коэффициент расширения.
                Если  f(vk)&lt;f(uk), то вершина xmax(k) заменяется на vk, в противном случае на uk и k-ая итерация заканчивается.
                Случай б): в результате отражения получается новая точка uk, которая, если заменить xmax(k), сама станет наихудшей. Поэтому в этом случае производится сжатие симплекса. Для этого строится точка vk:

                где  0&lt;&lt;1 –коэффициент сжатия.















                Если f(vk)&lt;min{f(xmax(k)),f(uk)}, то вершина xmax(k) заменяется на vk .
                В противном случае вершинам xi(k+1) (i=0,1,2,..,n) присваивается значение:
                и на этом k-ая итерация заканчивается.
                в)  вершина xmax(k) заменяется на uk, чем определяется набор вершин k+1-й  итерации и k –ая итерация заканчивается.
                Шаг 5. Проверка сходимости.
                Если
                то поиск минимума заканчивается и полагается
                В противном случае к=к+1 и происходит переход к шагу 2.
                Опыт использования описанного алгоритма показывает, что целесообразно брать следующие значения параметров:
                =1, =2, =0.5.


            </content>
        </topic>
        <topic>
            <name>14. Линейное программирование. Симплекс-метод</name>
            <content>
                Лекция 14 Линейное программирование. Симплекс-метод

                Линейное программирование - раздел математики, занимающийся решением таких задач на отыскание наибольших и наименьших значений, для которых методы математического анализа оказываются непригодными. К их числу относятся задачи на рациональное использование сырья и оборудования, на составление оптимального плана перевозок, работы транспорта и многие другие, принадлежащие сфере оптимального планирования.
                1. Постановка задачи линейного планирования.
                Задача линейного программирования может быть записана в произвольной форме записи, симметричной и канонической.
                Возьмём задачу линейного программирования, заданную в произвольной форме записи: максимизировать (минимизировать)
                (1.1)
                при ограничениях
                (1.2)
                (1.3)
                (1.4)
                (1.5)
                - произвольное      (1.6)
                Если в задаче линейного программирования требуется максимизировать целевую функцию (1.1) при ограничениях (1.2), (1.5), то задача задана в симметричной форме записи.
                Задача линейного программирования, в которой требуется найти максимум функции (1.1) при ограничениях (1.4), когда  , и (1.5), задана в канонической форме записи.
                При использовании тех или иных методов решения задач линейного программирования приходится осуществлять переходы от одной формы записи задачи к другой. Делается это путём следующих математических преобразований. Неравенства (1.2) путём умножения левых и правых частей на (-1) можно превратить в неравенства (1.3) и наоборот. Если в задаче какая-то переменная не подчинена условию неотрицательности (1.5), то её заменяют разностью двух других переменных. Например, произвольную переменную   заменяют на  , где   и  .
                Задачу минимизации можно формально заменить задачей максимизации. Минимальное значение функции f равно максимальному значению функции (-f), взятому с противоположным знаком, т.е.  .
                Преобразование неравенств в уравнения и уравнений в неравенства проводится на основании теоремы:
                всякому решению  неравенства
                (1)
                соответствует вполне определённое решение   уравнения
                (2)
                и неравенства
                ,    (3)
                и наоборот, каждому решению  уравнения (2) и неравенства (3) соответствует единственное решение  неравенства (1).
                Переменная   называется дополнительной или балансовой переменной.
                2.Графический метод решения.
                Графический метод используется для решения задач линейного программирования с двумя переменными, заданными в канонической форме (при условии, что они содержат не более двух свободных переменных).
                Задачу линейного программирования с двумя переменными можно записать так:
                (max);    (2.1)
                (2.2)
                (2.3)
                Область допустимых решений задачи (2.1)-(2.3) представляет собой либо выпуклый многоугольник, выпуклую многоугольную область, либо единственную точку, либо пустое множество.
                Рис. 2.1,
                Функция (2.1) представляет собой на плоскости X1OX2 семейство параллельных прямых, каждой из которых отвечает определённое значение f. Перпендикулярный к этим прямым вектор   указывает направление наискорейшего возрастания функции f, и задача (2.1)-(2.3) заключается в следующем: необходимо найти точку допустимой области, через которую проходит прямая семейства f, отвечающая наибольшему значению функции (рис.2.1(а)).
                При решении задачи линейного программирования графическим способом могут встретится следующие случаи: задача имеет единственное решение (рис.2.1(а)); задача имеет бесконечное множество решений (рис.2.1(б)); функция f не имеет экстремального значения (рис.2.1(в)).
                Решение задачи графическим способом проводится в такой последовательности:
                1). записывают уравнения граничных прямых   и строят их на плоскости X1OX2;
                2). определяют полуплоскости, соответствующие исходным ограничениям-неравенствам (2.2). Для этого берут произвольную точку, лежащую по ту или иную сторону от граничной прямой, и её координаты подставляют в левую часть ограничения-неравенства. Если оно удовлетворяется, то искомой будет полуплоскость, которая содержит выбранную точку; если не удовлетворяется, то искомой будет полуплоскость, которой данная точка не принадлежит;
                3). Выделяют область допустимых решений задачи как общую часть m+2 полуплоскостей, где m полуплоскостей соответствуют исходным неравенствам (2.2), а 2 полу-плоскости – условию неотрицательности переменных (2.3);
                4). строят вектор   и перпендикулярно к нему одну из прямых семейства f , например f=0;
                5). определяют экстремальную точку многоугольника решений путём параллельного перемещения вспомогательной прямой f=0 в направлении вектора . Это будет наиболее удалённая крайняя точка, в которой прямая f встречается с областью допустимых решений. Если необходимо найти точку, которой соответствует минимальное значение функции f , то вспомогательную прямую перемещают в направлении вектора   до пересечения с первой точкой допустимой области (либо прямую f=0 перемещают в направлении вектора  ).
                6). вычисляют координаты оптимальной точки и значения функции f.
                Задачу линейного программирования со многими переменными можно решить графическим способом, если она представлена в канонической форме и содержит не более двух свободных переменных, т.е.   где n - число переменных; r - ранг матрицы системы ограничений. При решении такой задачи прежде всего её приводят к эквивалентной задаче с двумя переменными, заданной в симметричной форме, затем полученную задачу решают графическим способом. Отделив координаты экстремальной точки, подставляют их в исходные ограничения-уравнения и находят значения остальных  переменных.
                3.Симплексный метод.
                3.1.Общая идея метода.
                Дана задача линейного программирования в канонической форме: максимизировать
                (3.1.1)
                при условии
                (3.1.2)
                .    (3.1.3)
                Предположим, что в системе (3.1.2)   и все   уравнений линейно независимы (ранг системы  ). В этом случае система имеет бесчисленное множество решений. Её можно разрешить относительно   переменных  , если векторы-коэффициенты   при этих переменных линейно независимы:
                .    (3.1.4)
                В этом случае   - базисные переменные, а   - свободные переменные. Тогда и целевую функцию можно выразить через свободные переменные  :
                .    (3.1.5)
                Если все  , то план  будет являться опорным планом и  . Если при этом опорном плане значение целевой функции максимально, то опорный план является оптимальным.
                Решение задачи (3.1.1)-(3.1.3) симплексным методом складывается их двух этапов:
                1) 	нахождение начального опорного плана;
                2) 	определение среди опорных планов задачи оптимального.
                Решение задачи проводится с использованием симплексных таблиц. Симплексная таблица, содержащая ограничения (3.1.4) и целевую функцию (3.1.5), имеет вид табл. (3.1.1).
                Таблица (3.1.1)
                БП	1	СП
                ...

                ...


                ...

                ...
                ...................
                ...


                ...
                3.2.Нахождение начального опорного плана.
                Задача (3.1.1)-(3.1.3) разрешена относительно базиса   и записана в симплексную табл. (3.1.1). Табл. (3.1.1) будет содержать начальный опорный план, если все элементы столбца свободных членов положительны, а свободные переменные равны нулю  . Если хотя бы один из свободных членов отрицательный, то табл. (3.1.1) опорного плана не содержит.
                Алгоритм нахождения начального опорного плана следующий:
                1) 	просматривают строку, содержащую отрицательный свободный член, например строку m , и по отрицательному элементу этой строки выбирают разрешающий столбец, например n-столбец. Если среди свободных членов несколько отрицательных, то согласимся просматривать строку, содержащую наибольший по абсолютной величине отрицательный свободный член. Если просматриваемая строка отрицательных элементов не содержит, то система ограничений несовместна, исходная задача решений не имеет;
                2) 	находят симплексные отношения для разрешающего столбца – отношения элементов столбца свободных членов к соответствующим элементам разрешающего столбца (причём симплексные отношения всегда больше или равны 0, так как составляются для элементов, имеющих одинаковые знаки);
                3) 	по наименьшему симплексному отношению определяют разрешающую строку, например m-строку;
                4) 	находят разрешающий элемент на пересечении разрешающего столбца и разрешающей строки (элемент  );
                5) 	с выбранным разрешающим элементом производят симплексное преобразование, получают новую симплексную таблицу – табл. (3.2.1).
                Таблица(3.2.1)
                БП	1	СП
                ...

                ...


                ...

                ...
                ...................
                ...


                ...
                В результате переменные   и   поменялись ролями:   стала базисной,   -- свободной.
                Элементы табл. (3.2.1) перечисляются по следующим правилам:
                	разрешающий элемент заменяется обратной величиной;
                	остальные элементы разрешающего столбца делятся на разрешающий элемент и меняют знак на противоположный;
                	остальные элементы разрешающей строки делятся на разрешающий элемент;
                	все прочие элементы таблицы вычисляются по формуле
                .
                Если в новой симплексной таблице получен начальный опорный план, то переходят к поиску оптимального, в противном случае процесс повторяется (опять возвращаемся к пункту 1) ).

                3.3.Нахождение оптимального плана.
                Если в симплексной таблице, содержащей опорный план, все элементы f-строки (не считая свободного члена) неотрицательны, то данный опорный план является оптимальным. Полученный оптимальный опорный план будет единственным, если все элементы f-строки положительны. Если среди неотрицательных элементов встречается хотя бы один нулевой, то задача имеет бесконечное множество оптимальных планов. Если хотя бы один элемент f-строки отрицательный, то оптимальный опорный план находят в соответствии со следующим алгоритмом:
                1) 	выбирают разрешающий столбец по отрицательному элементу f-строки (если в f-строке отрицательных элементов несколько, то наибольший по абсолютной величине отрицательный элемент укажет на разрешающий элемент);
                2) 	разрешающая строка определяется по минимальному симплексному отношению;
                3) 	делают симплексное преобразование с выбранным разрешающим элементом и получают новый опорный план, который опять проверяют на оптимальность. Решение проводится до тех пор, пока не будет получен оптимальный план, либо установлена неразрешимость задачи.
                Если в f-строке симплексной таблицы, содержащей опорный  план, есть хотя бы один отрицательный элемент, а в соответствующем этому элементу столбце нет ни одного положительного, то целевая функция не ограничена в области допустимых решений, т.е.   .

                4.Двойственный симплекс-метод.
                4.1 	Построение двойственной задачи.
                Каждой задаче линейного программирования можно поставить в соответствии задачу, называемую двойственной к исходной.
                Пусть имеем общую задачу линейного программирования, заданную в произвольной форме записи:
                (4.1.1)
                Двойственная задача по отношению к задаче (4.1.1) запишется следующим образом:
                (4.1.2)
                Для построения двойственной задачи необходимо соблюдать следующие правила:
                1) 	каждому i-му ограничению задачи (4.1.1) соответствует переменная yi задачи (4.1.2), и, наоборот, каждому j-му ограничению двойственной задачи (4.1.2) соответствует переменная xj задачи (4.1.1);
                2) 	матрица системы ограничений двойственной задачи получается из матрицы системы ограничений исходной задачи транспонированием, т.е. заменой строк столбцами, с сохранением их порядка;
                3) 	свободные члены ограничений задачи (4.1.1) являются коэффициентами при соответствующих переменных целевой функции двойственной задачи (4.1.2); аналогично коэффициенты целевой функции исходной задачи (4.1.1) совпадают со свободными членами системы ограничений двойственной задачи (4.1.2);
                4) 	если целевая функция исходной задачи (4.1.1) максимизируется, то целевая функция двойственной задачи (4.1.2) минимизируется;
                5) 	в задаче (4.1.1) ограничения-неравенства следует записывать со знаком  , а для задачи (4.1.2) – со знаком  ¬;
                6) 	если на j-ю переменную задачи (4.1.1) наложено условие неотрицательности, то j-е ограничение задачи (4.1.2) будет неравенством, в противном случае j-е ограничение будет равенством; аналогично связаны между собой ограничения задачи (4.1.1) и переменные задачи (4.1.2).

                4.2.Теоремы двойственности и двойственный симплекс-метод.
                Для пары взаимодвойственных задач (4.1.1), (4.1.2) имеет место первая теорема двойственности.
                Теорема . Если одна из задач двойственной пары имеет решение, то другая задача также имеет решение. При этом для любых оптимальных планов
                ,
                имеет место равенство

                Следствие. Для разрешимости одной из задач двойственной пары необходимо и достаточно, чтобы каждая из задач имела хотя бы одно решение.
                Следствие. Если целевая функция одной из задач двойст¬венной пары не ограничена, то другая задача не имеет решения.
                Следствие. Для оптимальности планов   и  пары двойственных задач необходимо и достаточно выполнение равенства

                Теорема. Для оптимальности допустимых планов х* и у* пары двойственных задач (4.1.1) и (4.1.2) соответственно необходимо и достаточно, чтобы они удовлетворяли системе уравнений:
                .
                Теорема имеет место для симметричной двойственной пары за¬дач. Она позволяет определить оптимальное решение одной из пары задач по решению другой. Это можно сделать с помощью таблицы пары взаимодвойственных задач (табл. 4.2.1).
                Таблица 4.2.1
                БП
                БП	F
                СП
                1




                1	f	0
                В табл. 4.2.1 значения базисных переменных исходной задачи определяются соответственно элементами F-го столбца двойственной задачи, а значения базисных переменных двойственной задачи — элементами f-и строки исходной задачи.
                Двойственный симплекс-метод. Пусть имеем исходную задачу линейного программирования в канонической форме записи:
                Двойственный симплекс-метод, или метод последовательного уточнения оценок, как и симплекс-метод, заключается в последовательном переходе от одного        n-мерного вектора к другому. Однако в отличие от симплекс-метода эти последовательно получаемые век¬торы не обязательно удовлетворяют условию неотрицательности.
                Двойственный симплекс-метод — это применение обычного симплекс-метода к двойственной задаче, дополненное построением на каждом шаге n-мерного вектора, являющегося почти допусти¬мым опорным решением данной задачи.
                Запишем двойственную к исходной задачу:
                .
                Алгоритм ее построения следующий:
                1) в F-й строке находится положительное число, которому со¬ответствует разрешающий столбец;
                2) в выделенном столбце отыскивается положительное число и содержащая его строка берется разрешающей; если в выделенном столбце нет положительных чисел, то задача не имеет решения;
                3) вычисляются двойственные модифицированные отношения элементов F-й строки соответственно к элементам разрешающей строки; отношение с наименьшей абсолютной величиной указывает разрешающий элемент.
                Первый этап решения заканчивается, если все коэффициенты (за исключением, возможно, свободного элемента) отрицательны. На втором этапе за разрешающую принимается строка с наименьшим отрицательным свободным членом; разрешающий столбец определя¬ется так же, как и на первом этапе.


            </content>
        </topic>
        <topic>
            <name>15. Сетевые модели. Динамическое программирование</name>
            <content>
                Лекция 15 Сетевые модели. Динамическое программирование.


            </content>
        </topic>
        <topic>
            <name>16. Моделирование случайных процессов. Имитационное моделирование</name>
            <content>
                Лекция 16 Моделирование случайных процессов. Имитационное моделирование.


            </content>
        </topic>
        <topic>
            <name>17. Системы массового обслуживания. Пуассоновские процессы</name>
            <content>
                Лекция 17 Системы массового обслуживания. Пуассоновские процессы.


            </content>
        </topic>
        <topic>
            <name>18. Особенности построения компьютерных моделей в различных предметных областях. Использование программных средств общего и специального назначения</name>
            <content>
                Лекция 18 Особенности построения компьютерных моделей в различных предметных областях. Использование программных средств общего и специального назначения.


            </content>
        </topic>
        <topic>
            <name>19. Моделирование в системах программирования</name>
            <content>
                Лекция 19 Моделирование в системах программирования.
                При компьютерном моделировании в первую очередь необходимо представить их математические модели в виде программ. Следовательно, большое значение при реализации модели имеет правильный выбор языка моделирования.
                Язык моделирования должен обеспечить:
                1)	удобство описания процесса функционирования системы,
                2)	удобство ввода исходных данных,
                3)	составление и варьирование структуры, параметров модели,
                4)	реализуемость как детерминированного, так и статистического моделирования.
                Эффективность языков моделирования существенно зависит от наличия диалоговых и графических средств. Удобство языка моделирования во многом определяется ориентацией на определенную предметную область. И, наконец, языки моделирования должны обеспечивать решение всех задач исследования и анализа результатов. Отсюда большое разнообразие языков моделирования. Был создан не один десяток языков и систем моделирования.
                В 50-е и 60-е годы прошлого века моделирование осуществлялось с помощью универсальных алгоритмических языков программирования. Таких как Фортран, Алгол, т.е. языков общего назначения. Применение таких языков требует высокой программистской квалификации. Вместе с тем программы получаются большими, громоздкими, требующими длительной отладки моделей. Ограничены возможности перестроить, видоизменить модель при необходимости. В результате такой способ программирования моделей малоэффективен, ненагляден и затруднителен для широкого пользователя.
                Позднее стали появляться системы моделирования, в основе которых был расширенный универсальный язык программирования. Расширение универсального языка, надстройка его учитывала специфику решаемого круга задач, специфику моделируемого объекта. К таким языковым средствам моделирования относится DSL (Digital Simulation Language) фирмы IBM для моделирования непрерывных систем.
                •	Дальнейшим развитием стала система CSMP(Continuous System Modeling Program – программа моделирования непрерывных систем; программа моделирования динамических характеристик систем), в основе которой были заранее запрограммированные функциональные блоки, наподобие блоков на аналоговых машинах. Расширенный ФОРТРАН в системе CSMP включал возможности обращения манипуляции этими блоками при разработке программы, реализующей ту или иную модель. Здесь широко используются операторы Фортрана. Однако в подобных системах большинство трудностей моделирования сохранилось.
                Подобные языки называют еще моделирующими языками высокого уровня или универсальными моделирующими языками.
                Разработан ряд моделирующих языков высокого уровня для моделирования дискретных систем, систем массового обслуживания. Таких, как SIMULA, SIMSCRIPT, GPSS, CSL и др.
                SIMULA представляет собой расширение языка АЛГОЛ, SIMSCRIPT — расширение Фортрана. Наибольшее распространение из этих языков получил язык GPSS. В GPSS важное место занимает обработка таких объектов, как транзакты (сообщения, заявки, запросы).
                Языки моделирования цифровых систем в основном обеспечивают задачи разработки цифровой аппаратуры. Их называют HDL или на русском языке — языки описания аппаратуры (ЯОА). Наиболее известным и эффективным ЯОА сегодня является язык VHDL.
                VHDL является единым, общим языком описания моделей и проектирования электронных устройств, начиная с вентильного, регистрового уровней и кончая уровнем описания вычислительных систем. Но основное назначением языка VHDL — описание заданий на моделирование.
                Для моделирования непрерывных динамических систем получил распространение язык CSMP, который реализует пакетный режим взаимодействия с пользователем. Появились и другие языки и системы моделирования непрерывных процессов, такие как MIDAS, PACTOLUS, CSSL. К отечественным языкам и системам моделирования непрерывных динамических систем относятся МАСЛИН и МАСС (разработанные сотрудниками МЭИ). Примерами языков, реализующих комбинированное моделирование являются GASP, НЕДИС и МИКС.
                GASP является расширением языка ФОРТРАН. Здесь непрерывные алгоритмы моделируются дифференциальными уравнениями, а дискретные процессы представляются в виде событий, наступление которых зависит от процесса функционирования системы. Событие — переход системы из одного состояния в другое в соответствии с принятыми правилами.
                НЕДИС — язык моделирования непрерывно-дискретных систем разработан сотрудниками Института кибернетики Академии наук Украины. НЕДИС создан на основе алгоритмических языков высокого уровня и относится к системам программирования универсального типа, т.е. языки GASP и НЕДИС относятся к процедурным языкам программирования.
                МИКС (моделирование имитационное комбинированных систем) представляет собой удобное средство моделирования. Как и язык МАСЛИН, МАСС система МИКС имеет в своей основе блочно-ориентированный язык с непроцедурной технологией программирования, позволяющей легко и быстро моделировать исследуемую систему, осуществлять быстрое преобразование модели, воспроизводить реально действующие сигналы и организовать вычислительный эксперимент. Блочные языки и соответствующие программные модули позволяют легко реализовать динамическое распределение памяти посредством размещения во внешнее запоминающее устройство (ВЗУ) больших библиотек модулей, извлекать их по мере необходимости, пересылать их в оперативную память.
                Нельзя не упомянуть здесь такие программные системы как MathCad, Matlab, Matrix, которые нашли применение для решения большого круга задач с помощью программ, реализующих широко используемые математические методы решения разнообразных уравнений и систем, задач оптимизации, линейного программирования, для отладки типовых алгоритмов регулирования, для решения задач идентификации и проектирования.
                Для нас интерес представляют средства моделирования, встроенные в упомянутые системы. В этих комплексных системах используются такие средства моделирования как SYSTEM BULD и SIMULINK. Языки моделирования этих средств блочно-ориентированные и близки к языку моделирования системы МАСС. Но поскольку SYSTEM BULD и SIMULINK являются подсистемами комплексных систем, то освоение технологии работы с ними требует дополнительных знаний помимо знания языка моделирования. Например, SIMULINK не может работать без матричной системы MATLAB. Другими словами, средствам моделирования в этих системах принадлежит вторичная роль.

                Моделирование, алгоритмизация и программирование
                В настоящее время в деятельности каждого человека возрастает доля умственного труда, требуется решать практические задачи, связанные с обработкой, хранением, передачей информации. В то же время растет число людей, профессионально занятых информационной работой. Для ее автоматизации применяется компьютер как универсальное средство работы с информацией.
                Решение задачи с применением компьютера предполагает следующие этапы:
                Рассмотрим подробнее каждый из перечисленных этапов.
                1. Постановка задачи. Построение информационной модели
                Как правило, практические задачи формулируются достаточно понятно с точки зрения пользователя, но такая формулировка не обладает достаточной четкостью и строгостью.
                Примеры:
                Чтобы такую задачу можно было решить с помощью компьютера, надо выполнить постановку задачи:
                Для этого важно определить существенные свойства объектов и явлений, о которых идет речь в задаче, и пренебречь несущественными.
                Иногда об этом забывают. Например, если в задаче требуется определить площадь верхней поверхности стола (столешницы), не задумываясь говорят, что надо измерить длину и ширину. Однако существенным свойством стола может оказаться то, что он круглый, тогда затруднительно вести речь о длине и ширине. Кроме того, даже если определили, что столешница имеет прямоугольную форму, следует договориться, что небольшие неровности не оказывают существенного влияния на величину площади.
                В примере с прямоугольным столом длина и ширина не могут быть отрицательными числами, а также иметь нереально большие или малые значения.
                Все эти сведения образуют информационную модель задачи.
                Главное свойство модели – упрощать изучаемое явление, сохраняя его существенные свойства. Информационной моделью задачи можно назвать информацию об объектах и явлениях, фигурирующих в задаче, значимую с точки зрения задачи и зафиксированную в текстовой, числовой или иной сигнальной форме.
                Шаги построения информационной модели:
                Дадим определение понятия «модель» и возможные классификации.
                Модель – это формализованное описание объекта, системы объектов, процесса или явления, выраженное математическими соотношениями, набором числе и (или) текстов, графиками, таблицами, словесными формулами и т.п.
                Процесс создания ( а иногда и исследования) модели называется моделированием.
                Метод познания, состоящий в исследовании объекта по его свойствам, называется моделированием.
                Классификация моделей
                По области использования
                Классификация с учетом фактора времени
                По способу представления
                По форме представления можно выделит следующие виды информационных моделей:
                2. Формализация задачи
                На этом этапе происходит фиксация информационной модели, выбирается форма представления данных, образующих информационную модель, наиболее удобная для компьютерной обработки. Часто первые два этапа не имеют четкой границы и могут рассматриваться как единое целое.
                Выполнив постановку задачи, создается формализованная модель, т. е. описательная информационная модель записывается с помощью какого-либо формального языка, например математического.
                3. Построение алгоритма
                Понятие алгоритма – одно из фундаментальных понятий информатики. Алгоритмизация наряду с моделированием выступает в качестве общего метода информатики.
                Алгоритмы являются объектом систематического исследования пограничной между математикой и информатикой научной дисциплины, примыкающей к математической логике – теории алгоритмов.
                Само слово «алгоритм» происходит от algorithmi – латинской формы написания имени великого математика IX века аль-Хорезми, который сформулировал правила выполнения арифметических действий. Первоначально под алгоритмами и понимали только правила выполнения четырех арифметических действий над многозначными числами.
                Алгоритм – понятное и точное предписание исполнителю совершить последовательность действий, направленных на достижение поставленной цели или решение поставленной задачи.
                Согласно этому определению рецепты изготовления какого-либо лекарства или печенья являются алгоритмами. И правило безопасного перехода пешеходом проезжей части улицы – тоже алгоритм. По своему назначению алгоритмы могут быть как «бытовыми», так и вычислительными.
                Исполнитель – это кто-то или что-то, умеющий выполнять некоторый вполне определенный набор действий.  Он обладает следующими свойствами:
                Вся совокупность команд, которые данный исполнитель умеет выполнять, называется системой команд исполнителя (СКИ).
                Формальное исполнение алгоритмов лежит в основе управления автоматическими устройствами. Действительно, простейшие операции, на которые при создании алгоритма расчленяется процесс решения задачи, может реализовать и машина, специально созданная для выполнения отдельных команд алгоритма и выполняющая их в последовательности, указанной в алгоритме.
                Однако и человек может быть формальным исполнителем. Если он не знает цели выполняемой работы, ему придется строго следовать инструкциям.
                Компьютер является формальным исполнителем алгоритмов. Чтобы он мог решать задачу в строгом соответствии с инструкциями, он должен получить алгоритм решения. Таким образом, алгоритм является управляющей информацией.
                Свойства  алгоритмов
                Дискретность алгоритма
                Исполнение алгоритма распадается на последовательность отдельных шагов. Выполнить каждый шаг предписывает команда. Таким образом, алгоритм представляет собой последовательность команд, определяющих действия исполнителя. Алгоритм имеет прерывистую (дискретную) структуру: только выполнив одну команду, исполнитель может приступить к выполнению следующей. Это свойство называется дискретностью.
                Понятность алгоритма
                Правильно составленный алгоритм содержит только те команды, которые входят в систему команд исполнителя, для которого он написан. Такое свойство называется понятностью.
                Понятными для исполнителя считаются те команды, которые он может выполнить.
                Например, человек, не умеющий складывать однозначные числа (не знающий таблицы сложения), не сможет воспользоваться описанным аль-Хорезми порядком сложения многозначных чисел.
                Точность алгоритма
                Важным свойством алгоритма является точность (определенность, однозначность). Каждая команда алгоритма должна однозначно восприниматься исполнителем и предполагать его определенное действие. Выполнив шаг алгоритма, исполнитель должен точно знать, какой шаг выполнять следующим. Примером неточного алгоритма является фраза из рецепта «всыпать 2-4 столовые ложки сахара» или классическое изречение «казнить нельзя помиловать».
                Результативность и конечность алгоритма
                Исполнение алгоритма должно приводить к получению результата (свойство результативности) за конечное число шагов (свойство конечности).
                Массовость алгоритма
                Желательно, чтобы алгоритм удовлетворял свойству массовости, т.е. мог быть применен для решения не только одной конкретной задачи, но и некоторого класса однотипных задач.
                Например, правило сложения многозначных чисел не зависит от количества разрядов в слагаемых или их цифрового состава. Оно работает, даже если число представлено не в десятичной системе счисления, а в позиционной системе счисления с любым целочисленным основанием.
                Способы записи алгоритмов
                На практике наиболее распространены следующие формы фиксации алгоритмов:
                Словесный способ
                Для человека основным является словесный способ.
                Словесный способ записи алгоритмов представляет собой описание последовательных этапов обработки данных. Алгоритм задается в произвольном изложении на естественном языке.
                Например. Записать алгоритм нахождения наибольшего общего делителя (НОД) двух натуральных чисел.
                Алгоритм может быть следующим:
                задать два числа;
                если числа равны, то взять любое из них в качестве ответа и остановиться, в противном случае продолжить выполнение алгоритма;
                определить большее из чисел;
                заменить большее из чисел разностью большего и меньшего из чисел;
                повторить алгоритм с шага 2.
                Описанный алгоритм применим к любым натуральным числам и должен приводить к решению поставленной задачи. Убедитесь в этом самостоятельно, определив с помощью этого алгоритма наибольший общий делитель чисел 125 и 75.
                Словесный способ не имеет широкого распространения по следующим причинам:
                Псевдокод
                Псевдокод – система обозначений и правил для единообразной и точной записи алгоритмов.
                Псевдокод ориентирован на человека, но облегчает перевод на язык программирования, поскольку требует соблюдения определенных правил записи. Примером псевдокода может служить школьный алгоритмический язык.
                Отметим, что между понятиями «алгоритмический язык» и «языки программирования» есть различие; прежде всего, под исполнителем в алгоритмическом языке может подразумеваться не только компьютер, но и устройство для работы «в обстановке». Программа, записанная на алгоритмическом языке, не обязательно предназначена компьютеру. Практическая же реализация алгоритмического языка – отдельный вопрос в каждом конкретном случае.
                Как и каждый язык, алгоритмический язык имеет свой словарь. Основу этого словаря составляют слова, употребляемые для записи команд, входящих в систему команд исполнителя того или иного алгоритма. Такие команды называют простыми командами. В алгоритмическом языке используют слова, смысл и способ употребления которых задан раз и навсегда. Эти слова называют служебными. Использование служебных слов делает запись алгоритма более наглядной, а форму представления различных алгоритмов – единообразной.
                Алгоритм, записанный на алгоритмическом языке, должен иметь название. Название желательно выбирать так, чтобы было ясно, решение какой задачи описывает данный алгоритм. Для выделения названия алгоритма перед ним записывают служебное слово АЛГ (АЛГоритм). За названием алгоритма (обычно с новой строки) записывают его команды. Для указания начала и конца алгоритма его команды заключают в пару служебных слов НАЧ (НАЧало) и КОН (КОНец). Команды записывают последовательно.
                Последовательность записи алгоритма:
                АЛГ название алгоритма
                НАЧ
                серия команд алгоритма
                КОН
                Графическое  представление  алгоритмов
                Алгоритм, составленный для некоторого исполнителя, можно представить различными способами: с помощью графического или словесного описания, в виде таблицы, последовательностью формул, записанным на алгоритмическом языке (языке программирования). Остановимся на графическом описании алгоритма, называемом блок-схемой. Этот способ имеет ряд преимуществ благодаря наглядности, обеспечивающей, в частности, высокую «читаемость» алгоритма и явное отображение управления в нем.
                Прежде всего определим понятие блок-схемы.
                Блок-схема – это ориентированный граф, указывающий порядок исполнения команд алгоритма.
                Блок-схема – это графическое представление алгоритма.
                В блок-схеме каждому типу действий (вводу исходных данных, вычислению значений выражений, проверке условий, управлению повторением действий, окончанию обработки и т.п.) соответствует геометрическая фигура, представленная в виде блочного символа. Блочные символы соединяются линиями переходов, определяющими очередность выполнения действий.
                В блок-схеме действия алгоритма (блоки) изображаются следующими геометрическими фигурами:
                Для организации действий в алгоритме применяют различные формы, называемые алгоритмическими конструкциями. Выделяют три основные алгоритмические конструкции: следование, ветвление, цикл. В математике доказана теорема о том, что любой алгоритм может быть составлен с использованием только этих трех алгоритмических конструкций, хотя существуют и другие конструкции, которые сокращают запись алгоритма, упрощают работу с ним, облегчают понимание.
                Конструкция следования (линейный алгоритм)
                Конструкция следования – это такая форма организации действий, когда действия выполняются последовательно, одно за другим.
                Здесь в качестве серий команд могут выступать:
                Фактически, каждый алгоритм можно разбить на достаточно крупные блоки, в состав которых войдут в различном порядке все перечисленные выше объекты, и из таких блоков составить линейный алгоритм.
                Пример
                Задача: вычислить площадь круга, если известен радиус.
                Дано: R - радиус круга.
                Найти: S - площадь круга.
                Решение: S=3,14 R2
                Выберем русский язык для записи алгоритма в этой форме и запишем последовательность команд, выполнение которых при заданном значении радиуса позволит найти площадь:
                Прочесть значение R.
                Умножить значение R на 3,14.
                Умножить результат второго действия на значение R.
                Записать полученный результат как значение S.
                На языке блок-схем
                Эта форма записи основана на замене типичных алгоритмических команд определенными геометрическими фигурами. Алгоритм решения этой задачи выглядит следующим образом (см. рис.).
                Конструкция ветвления
                Конструкция ветвления – это форма организации действий, при которой в зависимости от выполнения (невыполнения) некоторого условия выполняется одна из двух серий команд.
                Алгоритм, содержащий конструкцию ветвления, имеет разветвляющуюся структуру.
                Если &lt;условие&gt;
                то &lt;серия команд 1&gt;
                иначе &lt;серия команд 2&gt;
                конец ветвления
                Пример
                Задача: вычислить
                Дано: х – значение аргумента.
                Найти: у – значение функции.
                Решение:
                -x, если х&lt;0
                Вид получившейся графической схемы (см. рис.) объясняет, почему алгоритм, соответствующий ей назвали ветвящимся.
                Сделаем словесное представление данного алгоритма.
                Начало
                Если х&gt;0, то
                у: = х
                иначе
                начало
                у: = -х
                Конец ветвления
                Записать значение у
                Конец
                Выделяют полную и неполную условную конструкцию.
                Введём обозначение:
                Q – условие;
                P1, P2, … PN – действия, которые выполняются в случае истинности условия;
                T1, T2, … TN - действия, которые выполняются, если условие ложно.
                Блок-схема и алгоритм выглядят следующим образом (см. табл.):
                Условные конструкции
                Полная	Неполная
                Р1
                Р2
                …
                РN
                иначе
                Т1
                Т2
                …
                ТN
                Конец ветвления	Р1
                Р2
                …
                РN
                Конец ветвления.
                Конструкция цикла
                Конструкция цикла – это форма организации действий, при которой выполнение одной и той же последовательности действий повторяется несколько раз.
                Действия, выполнение которых надо повторять несколько раз, называются телом цикла. Тело цикла представляет собой серию команд. В алгоритме всегда должен присутствовать указатель, отделяющий тело цикла от основной части алгоритма.
                Различают два основных типа циклов: цикл с параметром и цикл с условием.
                Цикл с параметром
                Он применяется, когда количество повторений известно заранее.
                При этом параметр (переменная цикла) изменяется от своего начального значения до конечного с заданным шагом и определяет количество повторений.
                Запись цикла с параметром на алгоритмическом языке выглядит так:
                начальное            конечное                    шаг
                для &lt;имя параметра&gt; от &lt;   значение  &gt; до &lt;  значение  &gt; шаг &lt;изменения&gt;
                параметра            параметра               параметра
                нц
                &lt;тело цикла&gt;
                кц
                Цикл с условием
                Он применяется, когда количество повторений заранее неизвестно и зависит от выполнения некоторого условия.
                Различают циклы с предусловием и с постусловием.
                Цикл с предусловием (цикл «пока»)
                Проверка условия происходит перед очередным исполнением тела цикла.
                Запись на алгоритмическом языке и в виде блок-схемы:

                пока&lt;условие&gt;
                нц
                &lt; тело цикла &gt;
                кц
                Пока условие выполняется (соответствующее логическое выражение имеет значение «истина»), повторяется исполнение тела цикла. Как только условие перестало выполняться – прекращается исполнение цикла (выход по лжи).
                Если условие изначально не выполняется, тело цикла может не быть исполнено ни разу.
                Цикл с постусловием (цикл «до»)
                Проверка условия происходит после очередного исполнения тела цикла, т.е. тело цикла обязательно будет исполнено хотя бы один раз.


                повторять
                &lt; тело цикла &gt;
                до &lt; условие &gt;

                Исполнение тела цикла происходит, если условие не выполняется (соответствующее логическое выражение имеет значение «ложь»). Как только наступает выполнение условия, исполнение тела цикла прекращается (выход по истине).

                4. Составление программы
                Чтобы алгоритм мог быть выполнен компьютером, он должен быть записан на понятном ему языке. Однако компьютер воспринимает и может обрабатывать только двоичные коды (последовательности нулей и единиц). Следовательно, исходные данные и команды алгоритма должны быть представлены в двоичных кодах. Однако для человека это весьма неудобно, поэтому были разработаны языки, предназначенные для записи алгоритмов, которые, с одной стороны, близки естественным языкам, а с другой стороны, построены по достаточно строгим правилам, чтобы записанные на них алгоритмы можно было автоматически по формальным правилам перевести в двоичные коды. Такие языки называются языками программирования, а алгоритм, записанный на таком языке (так же, как и алгоритм, записанный в двоичных кодах), называется программой.
                С появлением персональных компьютеров этап составления алгоритма во многом соединяется с этапом программирования так же, как и со следующим этапом.
                Технологии программирования
                Алгоритмическое (модульное) программирование
                Основная идея алгоритмического программирования — разбиение программы на последовательность модулей, каждый из которых выполняет одно или несколько действий. Единственное требование к модулю — чтобы его выполнение всегда начиналось с первой команды и всегда заканчивалось на самой последней (то есть, чтобы нельзя было попасть на команды модуля извне и передать управление из модуля на другие команды в обход заключительной).
                Алгоритм на выбранном языке программирования записывается с помощью команд описания данных, вычисления значений и управления последовательностью выполнения программы.
                Текст программы представляет собой линейную последовательность операторов присваивания, цикла и условных операторов. Таким способом можно решать не очень сложные задачи и составлять программы, содержащие несколько сот строк кода.
                В таком программировании используются следующие элементы:
                Структурное программирование
                При создании средних по размеру приложений (несколько тысяч строк исходного кода) используется структурное программирование, идея которого заключается в том, что структура программы должна отражать структуру решаемой задачи, чтобы алгоритм решения был ясно виден из исходного текста. Для этого надо иметь средства для создания программы не только с помощью трех простых операторов, но и с помощью средств, более точно отражающих конкретную структуру алгоритма. С этой целью в программирование введено понятие подпрограммы — набора операторов, выполняющих нужное действие и не зависящих от других частей исходного кода. Программа разбивается на множество мелких подпрограмм (занимающих до 50 операторов — критический порог для быстрого понимания цели подпрограммы), каждая из которых выполняет одно из действий, предусмотренных исходным заданием. Комбинируя эти подпрограммы, удается формировать итоговый алгоритм уже не из простых операторов, а из законченных блоков кода, имеющих определенную смысловую нагрузку, причем обращаться к таким блокам можно по названиям. Получается, что подпрограммы — это новые операторы или операции языка, определяемые программистом.
                Возможность применения подпрограмм относит язык программирования к классу процедурных языков.
                Наличие подпрограмм позволяет вести проектирование и разработку приложения сверху вниз — такой подход называется нисходящим проектированием. Сначала выделяется несколько подпрограмм, решающих самые глобальные задачи (например, инициализация данных, главная часть и завершение), потом каждый из этих модулей детализируется на более низком уровне, разбиваясь в свою очередь на небольшое число других подпрограмм, и так происходит до тех пор, пока вся задача не окажется реализованной.
                Такой подход удобен тем, что позволяет человеку постоянно мыслить на предметном уровне, не опускаясь до конкретных операторов и переменных. Кроме того, появляется возможность некоторые подпрограммы не реализовывать сразу, а временно откладывать, пока не будут закончены другие части. Например, если имеется необходимость вычисления сложной математической функции, то выделяется отдельная подпрограмма такого вычисления, но реализуется она временно одним оператором, который просто присваивает заранее выбранное значение. Когда все приложение будет написано и отлажено, тогда можно приступить к реализации этой функции.
                Немаловажно, что небольшие подпрограммы значительно проще отлаживать, что существенно повышает общую надежность всей программы.
                Очень важная характеристика подпрограмм — это возможность их повторного использования. С интегрированными системами программирования поставляются большие библиотеки стандартных подпрограмм, которые позволяют значительно повысить производительность труда за счет использования чужой работы по созданию часто применяемых подпрограмм.
                Событийно-ориентированное программирование
                С активным распространением системы Windows и появлением визуальных RAD-сред широкую популярность приобрел событийный подход к созданию программ — событийно-ориентированное программирование.
                Идеология системы Windows основана на событиях. Щелкнул человек на кнопке, выбрал пункт меню, нажал на клавишу или кнопку мыши - в Windows генерируется подходящее сообщение, которое отсылается окну соответствующей программы. Структура программы, созданной с помощью событийного программирования, следующая. Главная часть представляет собой один бесконечный цикл, который опрашивает Windows, следя за тем, не появилось ли новое сообщение. При его обнаружении вызывается подпрограмма, ответственная за обработкусоответствующего события (обрабатываются не все события, их сотни, а только нужные), и подобный цикл опроса продолжается, пока не будет получено сообщение «Завершить работу».
                События могут быть пользовательскими, возникшими в результате действий пользователя, системными, возникающими в операционной системе (например, сообщения от таймера), и программными, генерируемыми самой программой (например, обнаружена ошибка и ее надо обработать).
                Событийное программирование является развитием идей нисходящего проектирования, когда постепенно определяются и детализируются реакции программы на различные события.
                Объектно-ориентированное программирование
                Развитие идей структурного и событийного программирования существенно подняло производительность труда программистов и позволило в разумные сроки (несколько месяцев) создавать приложения объемом в сотни тысяч строк. Однако такой объем уже приблизился к пределу возможностей человека, и потребовались новые технологии разработки программ.
                Объектно-ориентированное программирование базируется на понятиях объекта, класса и на трех ключевых концепциях — инкапсуляции, наследовании и полиморфизме.
                В языках программирования и реализовано понятие объекта как совокупности свойств(структур данных, характерных для этого объекта), и методов их обработки (подпрограмм изменения свойств) и событий, на которые данный объект может реагировать и которые приводят, как правило, к изменению свойств объекта.
                Объекты могут иметь идентичную структуру и отличаться только значениями свойств. В таких случаях в программе создается новый тип, основанный на единой структуре объекта (по аналогии с тем, как создаются новые типы для структур данных). Он называется классом, а каждый конкретный объект, имеющий структуру этого класса, называется экземпляром класса.
                Объединение данных c методами в одном типе (классе) называется инкапсуляцией. Помимо объединения, инкапсуляция позволяет ограничивать доступ к данным объектов и реализации методов классов. В результате у программистов появляется возможность использования готовых классов в своих приложениях на основе только описании этих классов.
                Важнейшая характеристика класса — возможность создания на его основе новых классов с наследованием всех его свойств и методов и добавлением собственных. Класс, не имеющий предшественника, называется базовым.
                Например, класс «студент» имеет свойства «ФИО», «год поступления», методы «посещать занятия» и «сдавать экзамены». Созданный на его основе класс «студент-заочник» наследует все эти свойства и методы, к которым дополнительно добавляется свойство «место работы» и метод «приезжать на сессию» Наследование позволяет создавать новые классы, повторно используя уже готовый исходный код и не тратя времени на его переписывание.
                В большинстве случаев методы базового класса у классов-наследников приходится переопределять — объект класса «студент-заочник» выполняет метод «посещать занятия» совсем не так, как объект класса «студент-очник». Все переопределяемые методы по написанию (названию) будут совпадать с методами базового объекта, однако компилятор по типу объекта (его классу) распознает, какой конкретно метод надо использовать, и не вызовет для объекта класса «студент-заочник» метод «посещать занятия» класса «студент». Такое свойство объектов переопределять методы наследуемого класса и корректно их использовать называется полиморфизмом.
                Примеры:
                1.	Инкапсуляция – объединение в объекте его свойств и возможных над ним операций (методов). Сочетание данных с допустимыми действиями над этими данными приводит к «рождению» нового элемента в конструировании программ – объекта и объект действует, так как в нем заложено, и только над тем, что в нем описано. Обращение к данным объекта не через его действия недопустимо. Объекты, инкапсулирующие одинаковый перечень свойств и операций, объединяются в классы. Каждый отдельный объект является экземпляром класса. Экземпляры класса могут иметь отличающиеся значения свойств.
                Например, файловая система компьютера может содержать сотни и тысячи файлов. Все файлы обладают одним и тем же набором свойств (имя, положение в файловой системе) и операций (переименование, перемещение или копирование) и образую класс объектов ФАЙЛЫ. Каждый отдельный файл является экземпляром этого класса и имеет конкретные значения свойств (имя, местоположение и др).
                2.	Наследование – определяет отношение между классами: объекты класса-потомок обладают всеми свойствами объектов класса-родитель. То есть каждый следующий производный объект наследует свойства, действия своих предшественников. Механизм наследования позволяет переопределить или добавить новые данные и методы их обработки, создать иерархию классов.
                Например. В векторных графических редакторах изображение строится из графических примитивов – точка, линия, окружность и т.д.
                Одним из графических примитивов является класс объектов ТОЧКА. В этом классе каждый объект обладает определенными свойствами (Координаты, Цвет), над которыми возможны соответствующие операции (Перемещение, Изменение цвета). Класс объектов ТОЧКА можно задать таблицей
                Свойства	Методы
                Координаты (x,y)	Перемещение
                Цвет	Изменение цвета
                Из класса объектов ТОЧКА можно получить новый класс ОКРУЖНОСТЬ, добавив новое свойство Радиус и операцию Изменение радиуса. Класс объектов ОКРУЖНОСТЬ можно задать таблицей.
                Свойства	Методы
                Координаты (x,y)	Перемещение
                Цвет	Изменение цвета
                Радиус (R)	Изменение радиуса
                Все объекты класса ОКРУЖНОСТЬ наследуют свойства и операции класса ТОЧКА. Класс ТОЧКА называется класс-родитель, класс ОКРУЖНОСТЬ – класс-потомок. Графически это выглядит так:


                наследование
                3.	Полиморфизм – возможность проведения одних и тех же операций над объектами, принадлежащими разным классам, при сохранении индивидуальных методов их реализации для каждого класса.  То есть одна и та же операция над объектами различных классов может выполняться различными методами.
                Например. Для большинства класса объектов в среде WINDOWS/OFFICE характерен набор одних и тех же операций – переименование, перемещение, копирование, удаление и т.д. Механизмы реализации этих действий неодинаковы для различных классов. Так, для копирования папки необходимо совершить последовательность действий по изменению файловой системы, а для копирования символа внести изменения в документ. Эти операции будут выполнятся различными программами.
                Визуальное программирование
                Технологии объектного, событийного и структурного программирования сегодня объединены в RAD-системах, которые содержат множество готовых классов, представленных в виде визуальных компонентов, которые добавляются в программу одним щелчком мыши. Программисту надо только спроектировать внешний вид окон своего приложения и определить обработку основных событий — какие операторы будут выполняться при нажатии на кнопки, при выборе пунктов меню или щелчках мышкой. Весь вспомогательный исходный код среда сгенерирует сама, позволяя программисту полностью сосредоточиться только на реализации алгоритма.
                Развитие этой технологии связано с появлением графического интерфейса. Это технология разработки приложений в виде графических объектов, с последующим переводом их в программный код. В 90-х годах появляется технология RAD – Rapid Application Development – быстрая разработка приложений. Все необходимые элементы оформления и управления создаются и обслуживаются не путем ручного программирования, а с помощью готовых визуальных компонентов, которые с помощью мыши перетаскиваются в проектируемое окно. Свойства и поведение компонентов настраиваются с помощью простых редакторов, визуально показывающих характеристики соответствующих элементов. При этом исходный текст программы генерируется RAD-средой автоматически.
                RAD-среды предназначены для разработки, при активном участии пользователей, информационных систем для бизнес-приложений. RAD призвана обеспечить высокую скорость разработки системы при одновременном повышении качества программного продукта и снижении его стоимости.
                Из универсальных языков программирования сегодня наиболее популярны следующие:
                Бейсик (Basic) — для освоения требует начальной подготовки (общеобразовательная школа);
                Паскаль (Pascal) — требует специальной подготовки (школы с углубленным
                изучением предмета и общетехнические вузы);
                Си++ (C++), Ява (Java), Си Шарп (С#) — требуют профессиональной подго-товки (специализированные средние и высшие учебные заведения).
                Для каждого из этих языков программирования сегодня имеется немало систем программирования, выпускаемых различными фирмами и ориентированных на различные модели ПК и операционные системы. Наиболее популярны следую¬щие визуальные среды быстрого проектирования программ для Windows:
                Basic: Microsoft Visual Basic;
                Pascal: Borland Delphi;
                C++: Microsoft Visual C++;
                Java: BorlandJBuilder,
                •          C#: Microsoft Visual Studio .NET, Borland С#Builder.
                Для разработки серверных и распределенных приложений можно использовать систему программирования Microsoft Visual C++, продукты фирмы Borland, прак¬тически любые средства программирования на java.
                5. Ввод программы в память компьютера. Пробный запуск
                На больших вычислительных центрах, при решении достаточно больших и сложных задач вводом программ занимаются люди специальной профессии – операторы ЭВМ. Кроме ввода программ операторы выполняют подготовку данных – ввод данных в память, запись их на внешние носители. Программист, работающий на ПК, вводит программу и данные сам.
                После того как программа введена, следует ее пробный запуск. В случаях, которые следует считать исключительными, программа исполняется сразу и выдает некоторый результат. Гораздо чаще приходится отыскивать причины, по которым программа не работает или работает не так, и исправлять их – отлаживать программу.
                6. Отладка и тестирование программы
                Процесс поиска и исправления ошибок в программе называется отладкой. Ошибки могут возникнуть при наборе, в результате нарушения правил записи программ на языке программирования – так называемые синтаксические ошибки. Обнаружить и исправить их помогают специальные инструментальные программы (программы синтаксического контроля), входящие в состав системы программирования. Система анализирует программу и выдает сообщение о месте и характере ошибки. Часто ошибки связаны с тем, что некоторая синтаксически правильная конструкция не может быть выполнена (например, деление на нуль или попытка присвоить величине целого типа вещественное значение). В этом случае также появляется сообщение о причине отказа и указывается, какая именно команда не может быть выполнена.
                Гораздо сложнее отыскать ошибки, допущенные при составлении алгоритма, которые, в конечном итоге, приводят к неправильной работе программы: отсутствие результата, зацикливание, неверный результат. В этом случае полезен бывает пошаговый контроль выполнения программы.
                Важным этапом процесса отладки является тестирование программы, т.е. испытание ее путем введения теста – определенного набора исходных данных, для которого результат работы отдельных блоков или программы в целом известен заранее.
                Часто в рамках разработки информационной модели накладываются ограничения на исходные данные. В этом случае программа должна реагировать на ввод неверных значений: останавливать работу или запрашивать повторный ввод. Как правило, в программе предусматривается защита от ввода неверных данных или от других непредусмотренных действий пользователя. Тогда в процессе тестирования проверяется качество такой защиты.
                Умение удачно подобрать такой тест, при котором ошибка (если она есть) наиболее вероятна, и предусмотреть разнообразные варианты хода вычислительного процесса, а также действия пользователя (порой весьма непредсказуемые), и, следовательно, защитить работу программы от всяких неожиданностей – большое искусство программиста.
                Простейший пример теста: если программа содержит ветвление, т.е. требуется выбор способа действий в зависимости от выполнения условия, надо проверять ее работу с теми исходными данными, при которых условие выполняется, и с теми, при которых оно не выполняется.
                До последнего времени 4, 5 и 6 этапы были необходимыми этапами решения задачи с помощью ЭВМ. При этом языки и системы программирования были теми программными инструментами, с помощью которых создавались новые программы для решения задач пользователя. Однако с расширением круга задач, для решения которых используется компьютер, растет число людей, которые, не будучи профессиональными программистами, применяют компьютер в своей работе.
                В связи с этим созданы разнообразные программные средства, которые являются основой информационных технологий, применяемых для решения разнообразных практических задач, таких, как обработка текстов и электронных таблиц, создание графических изображений, доступ к информации, хранящейся в базе данных, решение математической задачи, расчет технической конструкции и многое другое. Для их решения в распоряжении пользователя ЭВМ имеется обширное программное обеспечение.
                В процессе построения информационной модели задачи пользователь определяет, какие действия ему потребуется выполнить для достижения результата, и в соответствии с этим решает, каким программным средством  воспользоваться. Если в его распоряжении имеется программа, подходящая для решения данной задачи, то пользователь выбирает ее в качестве инструмента (СУБД, табличный процессор, математический пакет и др.). Если же готовым прикладным программным средством воспользоваться нельзя, придется использовать технологию программирования.
                7. Получение и анализ результатов
                Какая бы технология решения задач на компьютере ни использовалась, необходимым этапом будет получение и анализ результата: проверяется соответствие полученных результатов ожидаемому в рамках построенной информационной модели задачи, а также оценивается, насколько полученный результат соотносится с реальной практикой.
                На этом этапе выявляется, насколько построенная информационная модель соответствует реальности. Дело в том, что чем больше свойств объектов и явлений признано существенными и учтено, тем в большей степени модель отражает действительность. Однако учет большого числа характеристик ведет к усложнению модели, затруднениям в математическом выражении связей между характеристиками. Обычно стараются найти баланс между полнотой соответствия информационной модели реальному состоянию дел и ее сложностью в процессе уточнения модели (постепенного увеличения числа учитываемых существенных свойств).


            </content>
        </topic>
    </section>
</sections>